{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build a Multi-Agent Chatbot with CrewAI, ChromaDB, Gradio\n\n**Description:** Build a production-ready multi-agent chatbot with analyst and reviewer agents, ChromaDB RAG, CrewAI, and Gradio, delivering clearer, verified answers consistently.\n\n**ðŸ“– Read the full article:** [How to Build a Multi-Agent Chatbot with CrewAI, ChromaDB, Gradio](https://blog.thegenairevolution.com/article/how-to-build-a-multi-agent-chatbot-with-crewai-chromadb-gradio-3)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building a conversational chatbot with a multi\\-agent system? It sounds complicated, but honestly, once you break it into pieces, the whole thing becomes pretty manageable. Let me walk you through how I figured out how to create a chatbot that actually handles real conversations. We'll use specialized tools to pull information from documents, and here's the interesting part: we'll set up two agents. One digs up the information, the other double\\-checks everything. Works like a charm. If you want to understand [how transformer models power advanced conversational AI](/article/transformers-demystifying-the-magic-behind-large-language-models-2), I've written a guide that breaks it all down.\n\nFirst things first. You need a searchable knowledge base. Load your documents, break them into chunks, generate embeddings, store everything in a vector database with metadata. This way your chatbot finds accurate information fast, even with complex questions.\n\nThen comes the multi\\-agent workflow. Agent 1, the analyst, figures out what users want and gathers information using search tools. Provides an initial answer with references. Agent 2, the reviewer, checks the analyst's work before delivering the final response. We tie it together with a Gradio interface. Makes the whole thing easy to use.\n\n![Uploaded image](/public-objects/user_insert_44830763_1763760311490.png \"Uploaded image\")\n\n## Set up\n\nLet's start simple. Install what you need and load your API key.\n\nHere's your shopping list:\n\n* **LangChain**: Chains components together, handles conversations\n* **CrewAI**: Builds and manages your multi\\-agent workflow\n* **ChromaDB \\& LangChain\\-Chroma**: Your vector database\n* **LangChain\\-OpenAI**: OpenAI model integration\n* **Markdown**: Formats output text\n* **Gradio**: Creates the conversational UI\n* **Tqdm**: Shows progress indicators\n\nInstall everything:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install langchain langchain_chroma tqdm markdown langchain_openai chromadb crewai[tools] gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load your API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Index\n\nNow let's create an index from markdown files. I'm using the Bank of Canada Quarterly Financial Report, which I summarized in markdown. Got your own files? Skip ahead.\n\nStarting from scratch? Put your markdown files in a dedicated folder. The indexing loads these files, chunks the content, creates embeddings, stores everything in a searchable vector database. Actually, if you're interested in [alternative approaches to building chatbots that leverage structured data](/article/how-to-build-a-knowledge-graph-chatbot-with-neo4j-chainlit-gpt-4o-3), I wrote about building a knowledge graph chatbot with Neo4j and GPT\\-4o.\n\nLet's get started:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls markdown_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'Bank of Canada Quarterly Financial Report â€“ First Quarter 2023.md'\n'Bank of Canada Quarterly Financial Report â€“ First Quarter 2024.md'\n'Bank of Canada Quarterly Financial Report â€“ Second Quarter 2023.md'\n'Bank of Canada Quarterly Financial Report â€“ Second Quarter 2024.md'\n'Bank of Canada Quarterly Financial Report â€“ Third Quarter 2023.md'\n'Bank of Canada Quarterly Financial Report â€“ Third Quarter 2024.md'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!head -15 'markdown_files/Bank of Canada Quarterly Financial Report â€“ First Quarter 2023.md'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bank of Canada Quarterly Financial Report â€“ First Quarter 2023\n\n**For the period ended March 31, 2023**\n\n## Financial Position Overview\n\nAs of March 31, 2023, the Bank of Canada's total assets were **$374,712 million**, a **9% decrease** from **$410,710 million** on December 31, 2022. This reduction was primarily due to the maturity of investments. îˆ€citeîˆ‚turn0search0îˆ\n\n### Asset Breakdown\n\n- **Loans and Receivables**: Held steady at **$5 million**, unchanged from December 31, 2022.\n\n- **Investments**: Decreased by **9%** to **$344,766 million**, driven mainly by:\n- **Government of Canada Securities**: Declined due to bond maturities.\n- **Securities Repo Operations**: Reduced as the volume of these operations decreased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Split the Documents\n\nTime to load your markdown documents and split them into chunks. These chunks help the chatbot retrieve precise information quickly.\n\nHere's how:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.document_loaders import DirectoryLoader, TextLoader\nfrom langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n\nclass MarkdownProcessor:\n    def __init__(self, folder_path, file_pattern=\"./*.md\"):\n        self.folder_path = folder_path\n        self.file_pattern = file_pattern\n        self.loaded_docs = []\n        self.chunks = []\n        self.split_headers = [\n            (\"#\", \"Level 1\"),\n            (\"##\", \"Level 2\"),\n            (\"###\", \"Level 3\"),\n            (\"####\", \"Level 4\"),\n        ]\n\n    def load_markdown_files(self):\n        loader = DirectoryLoader(\n            path=self.folder_path,\n            glob=self.file_pattern,\n            loader_cls=TextLoader,\n        )\n        self.loaded_docs = loader.load()\n        print(f\"Documents loaded: {len(self.loaded_docs)}\")\n\n    def extract_chunks(self):\n        markdown_splitter = MarkdownHeaderTextSplitter(\n            headers_to_split_on=self.split_headers, \n            strip_headers=False\n        )\n        chunk_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=250, \n            chunk_overlap=30\n        )\n\n        for doc in self.loaded_docs:\n            markdown_sections = markdown_splitter.split_text(doc.page_content)\n\n            for section in markdown_sections:\n                # Keep metadata from the original document and add a custom tag\n                section.metadata = {\n                    **doc.metadata,\n                    **section.metadata,\n                    \"tag\": \"dev\"\n                }\n\n            chunks = chunk_splitter.split_documents(markdown_sections)\n            self.chunks.extend(chunks)\n\n            print(f\"Markdown sections for this doc: {len(markdown_sections)}\")\n            print(f\"Chunks for this doc: {len(chunks)}\")\n\n        print(f\"Total chunks created: {len(self.chunks)}\")\n\n# Run the processing\nmarkdown_processor = MarkdownProcessor(folder_path=\"./markdown_files\")\nmarkdown_processor.load_markdown_files()\nmarkdown_processor.extract_chunks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Documents loaded: 6\nMarkdown sections for this doc: 11\nChunks for this doc: 34\nMarkdown sections for this doc: 11\nChunks for this doc: 32\nMarkdown sections for this doc: 11\nChunks for this doc: 32\nMarkdown sections for this doc: 9\nChunks for this doc: 25\nMarkdown sections for this doc: 12\nChunks for this doc: 37\nMarkdown sections for this doc: 12\nChunks for this doc: 38\nTotal chunks created: 198"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "markdown_processor.chunks[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Document(metadata={'source': 'markdown_files/Bank of Canada Quarterly Financial Report â€“ First Quarter 2023.md', 'Level 1': 'Bank of Canada Quarterly Financial Report â€“ First Quarter 2023', 'Level 2': 'Financial Position Overview', 'Level 3': 'Asset Breakdown', 'tag': 'dev'}, page_content='### Asset Breakdown \\n- **Loans and Receivables**: Held steady at **$5 million**, unchanged from December 31, 2022. \\n- **Investments**: Decreased by **9%** to **$344,766 million**, driven mainly by:')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Vector Store\n\nChunks ready? Good. Generate embeddings and store them in a vector database. I use ChromaDB. It handles vector embeddings efficiently. While vector databases like ChromaDB work well, you can boost accuracy even more by [improving retrieval accuracy with cross\\-encoder reranking](/article/cross-encoder-reranking-the-low-cost-fix-for-rag-misses). I explained this technique in an article on RAG optimization.\n\nVector store setup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\nfrom langchain_openai import OpenAIEmbeddings\n\nclass VectorStoreBuilder:\n    def __init__(self, documents, storage_path='_md_db'):\n        self.documents = documents\n        self.storage_path = storage_path\n        self.vector_store = None\n\n    def build_and_save(self):\n        \"\"\"Creates and persists a Chroma vector store.\"\"\"\n        embedder = OpenAIEmbeddings()\n        self.vector_store = Chroma.from_documents(\n            documents=self.documents,\n            embedding=embedder,\n            persist_directory=self.storage_path\n        )\n        print(f\"Stored {len(self.vector_store.get()['documents'])} documents in vector store.\")\n\n# Build and save the vector store from the chunks created earlier\nvector_builder = VectorStoreBuilder(documents=markdown_processor.chunks)\nvector_builder.build_and_save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Stored 198 documents in vector store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Tools\n\nVector store ready? Now we create our multi\\-agent system. Define the tools our agents will use. For more on [building flexible and reliable tools for CrewAI agents](/article/how-to-build-flexible-tools-for-crewai-agents-2), including when to use decorators, BaseTool, or payloads, check out my guide.\n\nDefine these tools with CrewAI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai.tools import tool\nfrom typing import List\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_chroma import Chroma\n\n# ATTENTION: Ensure you use type annotations correctly, or the tools won't function properly.\n\n# Tool for searching relevant information from the vector store\n@tool(\"Search tools\")\ndef search_tool(query: str) -> List:\n    \"\"\"\n    Use this tool to retrieve relevant information to answer user queries.\n\n    Args:\n        query (str): The query used to search the vector store.\n\n    Returns:\n        List[Document]: Top-k documents matching the query.\n    \"\"\"\n    storage_path = 'md_db'  # Confirm this matches the path used above\n    k = 10\n    embedder = OpenAIEmbeddings()\n    vector_store = Chroma(persist_directory=storage_path, embedding_function=embedder)\n    results = vector_store.similarity_search(query, k=k)\n    return results\n\n# Tool for asking clarifying questions\n@tool(\"Ask for clarifications\")\ndef ask_for_clarifications(question: str) -> str:\n    \"\"\"Prompt the user for clarification.\"\"\"\n    print(f\"{question}\")\n    user_clarification = input()\n    return user_clarification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Multi\\-Agent Crew\n\nNow for the fun part. Two specialized agents:\n\n* **Analyst Agent**: Researches, creates detailed responses\n* **Reviewer Agent**: Checks and refines the Analyst's work\n\nDefine them like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew\n\n# Define the Analyst agent\nanalyst_agent = Agent(\n    role=\"Conversational Research and Analysis Specialist\",\n    goal=\"Interpret user requests, perform detailed research using the search tool, and compile comprehensive answers with reference documents.\",\n    backstory=(\n        \"With extensive experience in analytical research and data-driven insights, \"\n        \"you excel at breaking down complex queries, conducting targeted searches, \"\n        \"and synthesizing data into clear responses. Your methodical approach ensures \"\n        \"accuracy and comprehensiveness in every answer.\"\n    ),\n    verbose=True\n)\n\n# Define the Reviewer agent\nreviewer_agent = Agent(\n    role=\"Quality Assurance and Final Review Specialist\",\n    goal=\"Carefully review and refine the initial responses, correct inaccuracies, and deliver a final answer meeting high standards of quality and clarity.\",\n    backstory=(\n        \"With a keen eye for detail and extensive experience in quality control and content review, \"\n        \"you detect inconsistencies, validate sources, and polish answers. \"\n        \"Your meticulous approach ensures every final response is accurate, clear, and insightful.\"\n    ),\n    verbose=True\n)\n\n# Define the Analyst task (be cautious with the clarifications tool to avoid repetitive questioning)\nanalyst_task = Task(\n    description=\"\"\"# Follow these step-by-step instructions:\n1. Understand the user request: Read and analyze thoroughly, taking conversation history into account.\n2. [OPTIONAL] Only ask for clarifications if the request is unclear or not specifically about these topics:\n   - Bank of Canada Quarterly Financial Report\n     - Financial Position Overview\n       - Asset Breakdown\n       - Liabilities and Deficiency\n     - Results of Operations\n       - Interest Revenue and Expense\n       - Operating Expenses\n       - Comprehensive Income\n     - Financial Plan\n     - Operational Highlights and Changes\n     - Risk Analysis\n3. Use the search tool repeatedly as needed to collect relevant information.\n4. Perform any necessary calculations or analyses.\n5. Synthesize gathered data into a comprehensive response.\n6. Provide a detailed answer supported by references.\n\n# Conversation history:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{conversation_history}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# User request:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{user_request}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORTANT:\n- You MUST only use information found via the search tool.\n- Do NOT rely on external knowledge.\n\"\"\",\n    expected_output=(\n        \"A well-structured markdown-formatted answer, detailed and supported by reference documents and data. \"\n        \"DO NOT include triple backticks around the markdown. DO NOT include additional comments. Just respond with markdown.\"\n    ),\n    agent=analyst_agent,\n    tools=[search_tool, ask_for_clarifications]\n)\n\n# Define the Reviewer task\nreviewer_task = Task(\n    description=(\n        \"Follow these step-by-step instructions:\"\n        \"1. Review the Analyst's answer carefully.\"\n        \"2. Identify any errors, inconsistencies, or gaps.\"\n        \"3. Refine and correct the response to enhance clarity and accuracy.\"\n        \"4. Provide a polished final answer.\"\n    ),\n    expected_output=(\n        \"A finalized markdown-formatted answer ready for delivery. \"\n        \"DO NOT include triple backticks around the markdown. DO NOT include additional comments. Just respond with markdown.\"\n    ),\n    agent=reviewer_agent,\n    context=[analyst_task]\n)\n\n# Create the Crew with both agents and tasks\nanalyst_crew = Crew(\n    agents=[analyst_agent, reviewer_agent],\n    tasks=[analyst_task, reviewer_task],\n    verbose=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test your crew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = {\n    \"conversation_history\": \"\",\n    \"user_request\": \"Tell me about Liabilities and Deficiency in 2023\"\n}\nresult = analyst_crew.kickoff(inputs=inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Uploaded image](/public-objects/user_insert_44830763_1763759975180.png \"Uploaded image\")\n\n## Create the UI with Gradio\n\nFinally, build the conversational interface using Gradio. The interface handles user messages, invokes the agent crew, provides structured responses.\n\nImplementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\nfrom gradio import ChatMessage\nimport time\n\ndef analyst_chat(message, history):\n    start_time = time.time()\n    \n    # Initial thinking indicator\n    response = ChatMessage(\n        content=\"\",\n        metadata={\"title\": \"_Thinking_ step-by-step\", \"id\": 0, \"status\": \"pending\"}\n    )\n    yield response\n\n    # Prepare the inputs for the crew\n    inputs = {\n        \"conversation_history\": history,\n        \"user_request\": message\n    }\n\n    # Kick off the multi-agent workflow\n    result = analyst_crew.kickoff(inputs=inputs)\n\n    # Update the thinking status\n    response.metadata[\"status\"] = \"done\"\n    response.metadata[\"duration\"] = time.time() - start_time\n    yield response\n\n    # Return the final agent response\n    response = [\n        response,\n        ChatMessage(\n            content=result.raw\n        )\n    ]\n    yield response\n\n# Launch the Chat Interface\ndemo = gr.ChatInterface(\n    analyst_chat,\n    title=\"Analyst Chat\",\n    type=\"messages\",\n    flagging_mode=\"manual\",\n    flagging_options=[\"Like\", \"Spam\", \"Inappropriate\", \"Other\"],\n    save_history=True\n)\n\n# Remember: Restart kernel each time you make changes to reflect them\ndemo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "* Running on local URL: http://127.0.0.1:7860\n\nTo create a public link, set `share=True` in `launch()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Uploaded image](/public-objects/user_insert_44830763_1763760000747.png \"Uploaded image\")\n\n## Conclusion\n\nThere are lots of ways to build a conversational chatbot. But Gradio gives you real flexibility. It directs interactions to a specific Python function, so you can customize the chatbot's logic however you want. And since the chatbot logic is just regular Python functions, you can implement any behavior you can think of. Pretty straightforward for developers at any level.\n\nIn this project, you've seen how easy it is to integrate a multi\\-agent system with Gradio. The Analyst gathers information. The Reviewer ensures accuracy. Together they handle complex user interactions reliably. This multi\\-agent approach plus Gradio's interface creates a robust system that adapts to many scenarios, including detailed research tasks.\n\nLooking ahead, I'm planning to explore more capabilities. Like streaming step\\-by\\-step thoughts from agents directly into the UI. Also interested in more advanced interactive features, letting agents ask users clarifying questions during the conversation. As you explore features like dynamic questioning and richer conversational flows, you might benefit from [advanced prompt engineering and in\\-context learning techniques](/article/the-magic-of-in-context-learning-teach-your-llm-on-the-fly-3) to refine your chatbot's responses. These enhancements should make interactions more transparent and effective. Which is really what we're after."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build a Multi-Agent Chatbot with CrewAI, ChromaDB, Gradio",
    "description": "Build a production-ready multi-agent chatbot with analyst and reviewer agents, ChromaDB RAG, CrewAI, and Gradio, delivering clearer, verified answers consistently.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}