{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build Multi-Agent AI Systems with CrewAI and YAML\n\n**Description:** Build production-ready multi-agent AI systems with CrewAI using reusable YAML-first patterns, explicit tools and tasks, guardrails, and interactive training loops.\n\n**ðŸ“– Read the full article:** [How to Build Multi-Agent AI Systems with CrewAI and YAML](https://blog.thegenairevolution.com/article/how-to-build-multi-agent-ai-systems-with-crewai-and-yaml)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n\nThis guide walks you through building a multi\\-agent customer feedback analysis system with CrewAI. You'll define three specialized agentsâ€”one for sentiment evaluation, one for report summarization, and one for visualizationâ€”that collaborate in a structured workflow to process raw feedback, generate insights, and produce a final report with charts.\n\nYou'll see how to set up agents and tasks in YAML, integrate tools (in this case, a CSV file reader) for grounded analysis, validate structured outputs, and produce visualization snippets. All the code is ready to run (you can use Colab) with minimal setup.\n\nBy the end, you'll have a functioning multi\\-agent system that converts raw feedback data into reusable, structured analytical reports.\n\n## Building Blocks of Multi\\-Agent Systems in CrewAI\n\nWhen you build a multi\\-agent system, think of it like structuring a team. In CrewAI, you organize around Agents, Tasks, Tools, Crews, and Training. These are key to scaling and maintaining the system. CrewAI supports defining agents and tasks in YAML, which separates configuration from code. This makes things easier to manage and adjust over time.\n\n### Agents\n\nAgents represent roles, goals, and backstories. You define them in YAML. Each agent gets assigned tools (if needed), and memory or code permissions depending on their responsibilities. This keeps responsibilities explicit and helps reduce errors like hallucinations.\n\nIf you're interested in how agent design can be extended to more complex, stateful workflows, our guide on [building a stateful AI agent with LangGraph](link) offers a practical, step\\-by\\-step approach.\n\n### Tasks\n\nTasks are what you want agents to do. Each task has:\n\n* A description of what needs to be done\n* An expected output format\n* An agent assignment\n\nYou define tasks separately in YAML. You can have more tasks than agentsâ€”one agent may handle multiple tasks.\n\nFor a deeper dive into extracting structured information from unstructured data, see our article on [structured data extraction with LLMs](link), which explores building robust pipelines for production use.\n\n### Tools\n\nTools extend what agents can do. For customer feedback analysis, you'll want tools to read CSV files so agents can reference concrete feedback entries. CrewAI has built\\-in tools, and you can add custom ones.\n\nIf you're curious about how to optimize tool use and manage data access for agents, the [Model Context Protocol (MCP) guide](link) explains how to standardize tool and data access for reliable, auditable AI workflows.\n\n### Crews\n\nA Crew ties agents and tasks together into a workflow. You decide how agents collaborate. CrewAI supports several process types, including sequential workflows. Sequential means one task follows another. That gives you clarity in dependencies and results.\n\n## Creating a Multi\\-Agent Customer Feedback Analysis System\n\nLet's build a system that takes customer feedback data, analyzes sentiment and themes, creates summary tables, makes visualizations, and produces a final Markdown report.\n\n### Installing Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q 'crewai[tools]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import modules and load environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nimport os\nimport yaml\nfrom pathlib import Path\nfrom crewai import Agent, Task, Crew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the Agent Definitions\n\nMake an agents.yaml file with these agent definitions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```yaml\nfeedback_analysis_agent:\n  role: >\n    Customer Feedback Intelligence Specialist\n  goal: >\n    Thoroughly analyze customer feedback to identify sentiment nuances, detect recurring issues, and uncover product-specific insights using advanced natural language processing techniques.\n  backstory: >\n    With extensive experience in text analysis and data mining, you convert raw customer reviews into actionable insights that drive improvements in product quality and customer satisfaction.\n  verbose: true\n  allow_delegation: false\n\nsummary_report_agent:\n  role: >\n    Report Synthesis Expert\n  goal: >\n    Consolidate and structure the analyzed feedback into a comprehensive report, highlighting key metrics such as average ratings, sentiment distributions, and emerging trends.\n  backstory: >\n    You excel at transforming complex datasets into clear, actionable reports that empower stakeholders to make informed decisions.\n  verbose: true\n  allow_delegation: false\n\nvisualization_agent:\n  role: >\n    Data Visualization Specialist\n  goal: >\n    Generate intuitive and engaging visualizations using only pie charts rendered in Markdown-compatible Mermaid syntax, to illustrate sentiment breakdowns and product category engagement.\n  backstory: >\n    Your expertise in data visualization enables you to convert analytical findings into compelling, easily digestible graphics that integrate seamlessly into Markdown reports.\n  verbose: true\n  allow_delegation: false\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the Task Definitions\n\nMake a tasks.yaml file with these tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```yaml\nsentiment_evaluation:\n  description: >\n    Analyze each customer feedback record to accurately classify the sentiment as Positive, Negative, or Neutral.\n    Employ advanced text analytics to extract key themes, identify recurring issues, and capture nuanced sentiment from the feedback text.\n  expected_output: >\n    A comprehensive sentiment analysis report for each feedback entry, including sentiment labels, key themes, and detected issues.\n\nsummary_table_creation:\n  description: >\n    Aggregate critical metrics from the customer feedback data by creating summary tables.\n    Calculate average ratings, count feedback entries per product category, and summarize overall sentiment distributions.\n  expected_output: >\n    Well-organized tables presenting aggregated customer feedback metrics, prepared for visualization and reporting.\n\nchart_visualization:\n  description: >\n    Generate visual representations of the summary data using exclusively pie charts.\n    Utilize Mermaid syntax to create Markdown-compatible pie charts that display:\n    - Sentiment Distribution: The proportion of Positive, Neutral, and Negative feedback.\n    - Product Category Distribution: The share of feedback entries per product category.\n    Export the charts as Mermaid code snippets ready for embedding in Markdown documents.\n  expected_output: >\n    A collection of Mermaid-formatted pie charts that clearly visualize the key customer feedback metrics.\n\nfinal_report_assembly:\n  description: >\n    Integrate the sentiment analysis, summary tables, and Mermaid-generated pie charts into a cohesive final report.\n    The report should deliver clear insights, actionable recommendations, and highlight key trends in customer feedback.\n    Ensure that the final document is formatted for easy stakeholder consumption with embedded Markdown visualizations.\n  expected_output: >\n    A well-structured final report that seamlessly combines data analysis, visualizations, and actionable insights to guide decision-makers.\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Agents and Tasks Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_configurations(file_paths: dict) -> dict:\n    \"\"\"\n    Load YAML configurations from the specified file paths.\n\n    Args:\n        file_paths (dict): A dictionary mapping configuration names to file paths.\n\n    Returns:\n        dict: A dictionary with the loaded YAML configurations.\n    Raises:\n        FileNotFoundError: If any configuration file is not found.\n        yaml.YAMLError: If an error occurs during YAML parsing.\n    \"\"\"\n    configs = {}\n    for config_type, file_path in file_paths.items():\n        path = Path(file_path)\n        if not path.exists():\n            raise FileNotFoundError(f\"Configuration file '{file_path}' for '{config_type}' not found.\")\n        try:\n            configs[config_type] = yaml.safe_load(path.read_text())\n        except yaml.YAMLError as error:\n            raise yaml.YAMLError(f\"Error parsing YAML file '{file_path}': {error}\")\n    return configs\n\n# Define file paths for YAML configurations\nfiles = {\n    'agents': 'agents.yaml',\n    'tasks': 'tasks.yaml'\n}\n\n# Load configurations and assign to variables\nconfigs = load_configurations(files)\nagents_config = configs.get('agents')\ntasks_config = configs.get('tasks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the Tools\n\nYou can either create your own feedback dataset or use one you already have. In this example, we'll use the sample file from the GenAI Revolution Cookbooks repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom pathlib import Path\nfrom crewai_tools import FileReadTool\n\n# Define local file path\ncsv_path = Path(\"customer_feedback.csv\")\n\n# Load the CSV from GitHub\nurl = \"https://raw.githubusercontent.com/thegenairevolution/cookbooks/main/data/customer_feedback.csv\"\ndf = pd.read_csv(url)\n\n# Save a local copy\ndf.to_csv(csv_path, index=False)\nprint(f\"Customer feedback data saved locally at {csv_path}\")\n\n# Preview the first few rows\ndf.head()\n\n\n# Create csv_tool\ncsv_tool = FileReadTool(file_path='data/customer_feedback.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Agents, Tasks, and Crew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating Agents for Customer Feedback Analysis\nfeedback_analysis_agent = Agent(\n  config=agents_config['feedback_analysis_agent'],\n  tools=[csv_tool]\n)\n\nsummary_report_agent = Agent(\n  config=agents_config['summary_report_agent'],\n  tools=[csv_tool]\n)\n\nvisualization_agent = Agent(\n  config=agents_config['visualization_agent'],\n  allow_code_execution=False\n)\n\n# Creating Tasks\nsentiment_evaluation = Task(\n  config=tasks_config['sentiment_evaluation'],\n  agent=feedback_analysis_agent\n)\n\nsummary_table_creation = Task(\n  config=tasks_config['summary_table_creation'],\n  agent=summary_report_agent\n)\n\nchart_visualization = Task(\n  config=tasks_config['chart_visualization'],\n  agent=visualization_agent\n)\n\nfinal_report_assembly = Task(\n  config=tasks_config['final_report_assembly'],\n  agent=summary_report_agent,\n  context=[sentiment_evaluation, summary_table_creation, chart_visualization]\n)\n\n# Creating the Customer Feedback Crew\ncustomer_feedback_crew = Crew(\n  agents=[\n    feedback_analysis_agent,\n    summary_report_agent,\n    visualization_agent\n  ],\n  tasks=[\n    sentiment_evaluation,\n    summary_table_creation,\n    chart_visualization,\n    final_report_assembly\n  ],\n  verbose=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kicking Off Your Customer Feedback Analyst Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = customer_feedback_crew.kickoff()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the final result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\ndisplay(Markdown(result.raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nYou now have a clear example of how to use CrewAI to build a customer feedback analysis system. You defined your agents and tasks in YAML. You integrated a tool to read the CSV feedback data. You set up a workflow that moves from sentiment evaluation to report summarization to visualization and then final report assembly. The arrangement lets each part reference earlier outputs. Configuration lives outside code, so you can version control it or adjust it later.\n\nFor those looking to compare this approach with other agent architectures, you might find our tutorial on [building an LLM agent from scratch with GPT\\-4 ReAct](link) insightful, as it covers tool actions and control loops in detail.\n\nYou may want to extend this by enabling training mode so you can correct agents iteratively. Or try allowing parallel or hybrid process types if some tasks don't depend on earlier ones. If you want to go further, consider exploring structured data extraction pipelines with external tools or compare with ReAct\\-style agents trained from scratch for different trade\\-offs."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build Multi-Agent AI Systems with CrewAI and YAML",
    "description": "Build production-ready multi-agent AI systems with CrewAI using reusable YAML-first patterns, explicit tools and tasks, guardrails, and interactive training loops.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}