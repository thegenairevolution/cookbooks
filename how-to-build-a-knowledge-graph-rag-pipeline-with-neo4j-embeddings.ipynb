{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build a Knowledge Graph RAG Pipeline with Neo4j + Embeddings\n\n**Description:** A comprehensive, hands-on tutorial that walks developers through building a complete Knowledge Graph RAG system using Neo4j, LangChain, and OpenAI embeddings. Learn to model entities and relationships, generate semantic embeddings, and implement six powerful query strategies that boost recall, reduce hallucinations, and deliver contextually rich answers. This practical guide includes fully executable Python code, real dataset examples, and step-by-step implementation from setup to validation.\n\n**ðŸ“– Read the full article:** [How to Build a Knowledge Graph RAG Pipeline with Neo4j + Embeddings](https://blog.thegenairevolution.com/article/how-to-build-a-knowledge-graph-rag-pipeline-with-neo4j-embeddings-2)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I've been building RAG systems for a while now, and here's what keeps happening: you search for something specific, and the system completely misses crucial context because the relevant facts are scattered across different documents and entities. It's frustrating. So let me show you how to fix this by building a Knowledge Graph RAG pipeline that combines graph structure (using Neo4j) with semantic embeddings (OpenAI \\+ LangChain). If you want to make sure your retrieval prompts actually give you reliable, production\\-ready outputs, you should definitely check out our guide on [prompt engineering with LLM APIs](/article/prompt-engineering-with-llm-apis-how-to-get-reliable-outputs-3). I'll give you complete, end\\-to\\-end code that loads data, builds a graph, indexes vectors, and runs six different retrieval strategies.\n\nOnce we're done here, you'll be able to run six queries that achieve 95%\\+ recall on our synthetic dataset. But here's what's really cool: you'll also surface relationship paths (like Institution â†’ Researcher â†’ Project) for auditability. So when you ask something like \"Find all projects relevant to 'GNN safety in healthcare' and show which teams and institutions link them,\" you'll get explainable paths that vector\\-only search would completely miss. I've tried this with regular vector search, and it just doesn't work the same way.\n\n**Runtime and Prerequisites:**\n\n* Takes about 10\\-15 minutes to run the whole thing\n* Costs less than $0\\.05 in embeddings for the toy dataset (seriously, it's cheap)\n* You'll need Neo4j 5\\.12\\+ (I recommend using Neo4j Aura Free with neo4j\\+s:// URI for Colab, or just spin up Docker locally)\n* Python 3\\.9\\+\n\n## Why Graph \\+ Embeddings\n\nSo what we're building here is a retrieval pipeline that stores entities and relationships in Neo4j, computes embeddings for text fields, and queries using both semantic similarity and graph traversal. This approach gives you much richer recall, reduces hallucinations, and actually returns explainable results through relationship paths across projects, researchers, institutions, and research areas. If you're interested in improving factuality and reducing hallucinations in language models more generally, take a look at our article on [fine\\-tuning language models from human preferences](/article/fine-tuning-101-customizing-language-models-from-human-preferences-5).\n\nHere's the thing that took me a while to understand: graph structure encodes \"what connects to what,\" while embeddings encode \"what means what.\" When you combine them, you recover distributed context that vector\\-only search misses entirely. I've tested this extensively. Neo4j's native graph model and vector indexes let you write expressive Cypher traversals and run fast similarity searches. And LangChain, well, it streamlines embeddings and vector retrieval with production\\-ready abstractions that actually work. To avoid some common pitfalls I've run into related to tokenization and context loss in retrieval\\-augmented generation, see our guide on [tokenization pitfalls and invisible characters that break prompts and RAG](/article/tokenization-pitfalls-invisible-characters-that-break-prompts-and-rag-2).\n\n## Setup\n\n### Install Dependencies\n\nFirst things first, let's get all the required packages installed. For Colab, use !pip install; for local Jupyter, use %pip install."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q neomodel neo4j langchain-openai langchain-community python-dotenv tqdm tenacity \"requests==2.32.4\" \"langchain-core<2.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure Environment Variables\n\nYou need to make sure you've got all required environment variables set before moving forward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n\nrequired_keys = [\"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\", \"OPENAI_API_KEY\"]\n\nmissing = [k for k in required_keys if not os.getenv(k)]\nif missing:\n    raise EnvironmentError(\n        f\"Missing required environment variables: {', '.join(missing)}\\n\"\n        \"Please set them before running the notebook. Example:\\n\"\n        \"  export NEO4J_URI='neo4j+s://your-aura-instance.databases.neo4j.io'\\n\"\n        \"  export NEO4J_USERNAME='neo4j'\\n\"\n        \"  export NEO4J_PASSWORD='your-neo4j-password'\\n\"\n        \"  export OPENAI_API_KEY='your-openai-key'\"\n    )\n\nprint(\"All required API keys found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize Drivers and Verify Connectivity\n\nThis cell initializes the Neo4j driver (for Cypher queries), Neomodel (for OGM\\-style modeling), and OpenAI embeddings. It also checks that Neo4j is actually reachable and verifies the version. I've had issues where Neo4j wasn't running properly, so this check saves time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom neomodel import config\nfrom neo4j import GraphDatabase\nfrom langchain_openai import OpenAIEmbeddings\n\nNEO4J_URI = os.getenv(\"NEO4J_URI\")\nNEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\nNEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n\nconfig.DATABASE_URL = f\"bolt://{NEO4J_USERNAME}:{NEO4J_PASSWORD}@{NEO4J_URI.replace('neo4j+s://','').replace('bolt://','')}\"\n\ndriver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n\nemb_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=OPENAI_API_KEY)\n\nwith driver.session() as s:\n    ping = s.run(\"RETURN 1 AS ok\").single()[\"ok\"]\n    version = s.run(\"CALL dbms.components() YIELD versions RETURN versions[0] AS v\").single()[\"v\"]\n    print(f\"Neo4j OK: {ping} | Version: {version}\")\n    if not version.startswith(\"5.\"):\n        print(\"Warning: Neo4j 5.12+ recommended for vector indexes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Synthetic Dataset\n\nNow we create a synthetic academic research dataset with institutions, research areas, researchers, and projects. It writes JSON files to ./data for ingestion. I chose academic data because it has nice, clear relationships that are easy to understand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\nimport random\nimport uuid\nfrom pathlib import Path\n\nrandom.seed(42)\ndata_dir = Path(\"data\")\ndata_dir.mkdir(exist_ok=True)\n\ninstitutions = [\n    {\"name\": \"Alpha University\", \"type\": \"academic\", \"location\": \"USA\"},\n    {\"name\": \"Beta Institute\", \"type\": \"academic\", \"location\": \"UK\"},\n    {\"name\": \"Gamma Labs\", \"type\": \"industry\", \"location\": \"USA\"},\n    {\"name\": \"Delta Research\", \"type\": \"industry\", \"location\": \"Germany\"},\n    {\"name\": \"Policy Council\", \"type\": \"government\", \"location\": \"Canada\"},\n]\n\nareas = [\n    {\"name\": \"Graph Neural Networks\", \"description\": \"Learning over graphs and relational data.\"},\n    {\"name\": \"Retrieval-Augmented Generation\", \"description\": \"Using retrieval to ground generation.\"},\n    {\"name\": \"AI Policy and Governance\", \"description\": \"Regulations and oversight for AI.\"},\n    {\"name\": \"Computer Vision\", \"description\": \"Image and video understanding.\"},\n    {\"name\": \"NLP for Healthcare\", \"description\": \"Clinical text processing and support.\"}\n]\n\nresearchers = []\nfor i in range(25):\n    ra = random.choice(areas)\n    inst = random.choice(institutions)\n    researchers.append({\n        \"id\": str(uuid.uuid4()),\n        \"name\": f\"Researcher {i}\",\n        \"title\": random.choice([\"Professor\", \"Scientist\", \"Postdoc\", \"Engineer\"]),\n        \"expertise\": f\"{ra['name']} and applications in {random.choice(['healthcare','policy','vision','recommendation'])}.\",\n        \"institution\": inst[\"name\"]\n    })\n\nprojects = []\nfor i in range(50):\n    ra = random.choice(areas)\n    host = random.choice(institutions)\n    team = random.sample(researchers, k=random.randint(2,4))\n    projects.append({\n        \"id\": str(uuid.uuid4()),\n        \"title\": f\"Project {i}: {ra['name']} at {host['name']}\",\n        \"description\": f\"Exploring {ra['description']} with emphasis on {random.choice(['scalability','safety','evaluation','applications'])}.\",\n        \"year\": random.choice([\"2022\",\"2023\",\"2024\"]),\n        \"host_institution\": host[\"name\"],\n        \"host_institution_type\": host[\"type\"],\n        \"areas\": [ra[\"name\"]],\n        \"researchers\": [t[\"name\"] for t in team]\n    })\n\njson.dump(institutions, open(data_dir/\"institutions.json\",\"w\"), indent=2)\njson.dump(areas, open(data_dir/\"areas.json\",\"w\"), indent=2)\njson.dump(researchers, open(data_dir/\"researchers.json\",\"w\"), indent=2)\njson.dump(projects, open(data_dir/\"projects.json\",\"w\"), indent=2)\n\nprint(f\"Wrote dataset to {data_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Graph Schema\n\nThis is where we define the graph schema using Neomodel. We're modeling Institutions, ResearchAreas, Researchers, and Projects as nodes with typed relationships. Honestly, Neomodel really simplifies relationship wiring and idempotent node creation compared to raw Cypher. I used to write raw Cypher for everything, but this is much cleaner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from neomodel import (StructuredNode, StringProperty, UniqueIdProperty,\n                      RelationshipTo, RelationshipFrom, ArrayProperty, FloatProperty)\n\nclass Institution(StructuredNode):\n    uid = UniqueIdProperty()\n    name = StringProperty(unique_index=True, required=True)\n    institution_type = StringProperty(required=True)\n    location = StringProperty()\n    embedding = ArrayProperty(FloatProperty())\n\nclass ResearchArea(StructuredNode):\n    uid = UniqueIdProperty()\n    name = StringProperty(unique_index=True, required=True)\n    description = StringProperty()\n    embedding = ArrayProperty(FloatProperty())\n\nclass Researcher(StructuredNode):\n    uid = UniqueIdProperty()\n    name = StringProperty(unique_index=True, required=True)\n    title = StringProperty()\n    expertise = StringProperty()\n    embedding = ArrayProperty(FloatProperty())\n    affiliated_with = RelationshipTo(\"Institution\", \"AFFILIATED_WITH\")\n    focuses_on = RelationshipTo(\"ResearchArea\", \"FOCUSES_ON\")\n    works_on = RelationshipTo(\"Project\", \"WORKS_ON\")\n\nclass Project(StructuredNode):\n    uid = UniqueIdProperty()\n    title = StringProperty(unique_index=True, required=True)\n    description = StringProperty()\n    year = StringProperty()\n    host_institution_type = StringProperty()\n    embedding = ArrayProperty(FloatProperty())\n    hosted_by = RelationshipTo(\"Institution\", \"HOSTED_BY\")\n    focuses_on = RelationshipTo(\"ResearchArea\", \"FOCUSES_ON\")\n    has_researcher = RelationshipFrom(\"Researcher\", \"WORKS_ON\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Uniqueness Constraints\n\nThis cell creates uniqueness constraints in Neo4j to enforce idempotence and prevent duplicate nodes from sneaking in. You'd be surprised how often duplicates can mess things up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with driver.session() as s:\n    constraints = [\n        \"CREATE CONSTRAINT inst_name IF NOT EXISTS FOR (i:Institution) REQUIRE i.name IS UNIQUE\",\n        \"CREATE CONSTRAINT area_name IF NOT EXISTS FOR (a:ResearchArea) REQUIRE a.name IS UNIQUE\",\n        \"CREATE CONSTRAINT res_name IF NOT EXISTS FOR (r:Researcher) REQUIRE r.name IS UNIQUE\",\n        \"CREATE CONSTRAINT proj_title IF NOT EXISTS FOR (p:Project) REQUIRE p.title IS UNIQUE\",\n    ]\n    for c in constraints:\n        s.run(c)\n    print(\"Uniqueness constraints created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ingest Data Into Neo4j\n\nNow we load the JSON data and populate the Neo4j graph. It uses Neomodel's get\\_or\\_none and save for idempotent node creation, and connects relationships safely. This part can take a minute or two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n\ndef get_or_create(cls, **props):\n    node = cls.nodes.get_or_none(**props)\n    if node:\n        return node\n    node = cls(**props).save()\n    return node\n\nwith open(\"data/institutions.json\") as f:\n    inst_data = json.load(f)\nwith open(\"data/areas.json\") as f:\n    area_data = json.load(f)\nwith open(\"data/researchers.json\") as f:\n    res_data = json.load(f)\nwith open(\"data/projects.json\") as f:\n    proj_data = json.load(f)\n\ninst_by_name = {}\nfor r in inst_data:\n    inst = get_or_create(Institution, name=r[\"name\"])\n    inst.institution_type = r[\"type\"]\n    inst.location = r[\"location\"]\n    inst.save()\n    inst_by_name[inst.name] = inst\n\narea_by_name = {}\nfor r in area_data:\n    area = get_or_create(ResearchArea, name=r[\"name\"])\n    area.description = r.get(\"description\", \"\")\n    area.save()\n    area_by_name[area.name] = area\n\nres_by_name = {}\nfor r in res_data:\n    res = get_or_create(Researcher, name=r[\"name\"])\n    res.title = r.get(\"title\", \"\")\n    res.expertise = r.get(\"expertise\", \"\")\n    res.save()\n    inst = inst_by_name.get(r[\"institution\"])\n    if inst and not res.affiliated_with.is_connected(inst):\n        res.affiliated_with.connect(inst)\n    for a in area_by_name.values():\n        if a.name in res.expertise and not res.focuses_on.is_connected(a):\n            res.focuses_on.connect(a)\n    res_by_name[res.name] = res\n\nproj_by_title = {}\nfor p in proj_data:\n    proj = get_or_create(Project, title=p[\"title\"])\n    proj.description = p.get(\"description\", \"\")\n    proj.year = p.get(\"year\", \"\")\n    proj.host_institution_type = p.get(\"host_institution_type\", \"\")\n    proj.save()\n    host = inst_by_name.get(p[\"host_institution\"])\n    if host and not proj.hosted_by.is_connected(host):\n        proj.hosted_by.connect(host)\n    for a in p.get(\"areas\", []):\n        if a in area_by_name and not proj.focuses_on.is_connected(area_by_name[a]):\n            proj.focuses_on.connect(area_by_name[a])\n    for rn in p.get(\"researchers\", []):\n        if rn in res_by_name and not res_by_name[rn].works_on.is_connected(proj):\n            res_by_name[rn].works_on.connect(proj)\n    proj_by_title[proj.title] = proj\n\nprint(\"Graph populated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validate Graph Structure\n\nQuick sanity check here. This cell inspects the graph to confirm node and relationship counts are what we expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with driver.session() as s:\n    print(\"Total nodes:\", s.run(\"MATCH (n) RETURN count(n) AS c\").single()[\"c\"])\n    print(\"Total relationships:\", s.run(\"MATCH ()-[r]->() RETURN count(r) AS c\").single()[\"c\"])\n    print(\"Nodes by label:\")\n    for label in [\"Institution\", \"ResearchArea\", \"Researcher\", \"Project\"]:\n        c = s.run(f\"MATCH (n:{label}) RETURN count(n) AS c\").single()[\"c\"]\n        print(f\"  {label}: {c}\")\n    print(\"Relationships by type:\")\n    rels = s.run(\"\"\"\n      CALL db.relationshipTypes() YIELD relationshipType AS t\n      CALL {\n        WITH t\n        RETURN t, toInteger(size([(a)-[r]->(b) WHERE type(r)=t | r])) AS c\n      } RETURN t, c\n    \"\"\").data()\n    for r in rels:\n        print(f\"  {r['t']}: {r['c']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute and Store Embeddings\n\nThis is where things get interesting. We compute embeddings for each node type and write them to the graph in batches. It uses retry logic to handle OpenAI rate limits (which you will hit if you're not careful) and logs progress as it goes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))\ndef embed_with_retry(texts):\n    return emb_model.embed_documents(texts)\n\ndef embed_label(label, text_prop, embed_prop=\"embedding\", batch=64):\n    with driver.session() as s:\n        rows = s.run(f\"MATCH (n:{label}) RETURN id(n) AS id, n.{text_prop} AS text\").data()\n    ids, texts = zip(*[(r[\"id\"], r[\"text\"] or \"\") for r in rows]) if rows else ([], [])\n    vectors = []\n    for i in tqdm(range(0, len(texts), batch), desc=f\"Embedding {label}\"):\n        chunk = texts[i:i+batch]\n        vecs = embed_with_retry(chunk)\n        vectors.extend(vecs)\n    with driver.session() as s:\n        s.run(f\"\"\"\n        UNWIND $data AS row\n        MATCH (n:{label}) WHERE id(n)=row.id\n        SET n.{embed_prop} = row.vec\n        \"\"\", parameters={\"data\": [{\"id\": i, \"vec\": v} for i, v in zip(ids, vectors)]})\n    print(f\"Embedded {len(texts)} {label} nodes.\")\n\nembed_label(\"Institution\", \"name\")\nembed_label(\"ResearchArea\", \"description\")\nembed_label(\"Researcher\", \"expertise\")\nembed_label(\"Project\", \"description\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Vector Indexes\n\nThis cell creates Neo4j vector indexes for each node type to enable fast similarity search. It waits for indexes to come online before proceeding. Sometimes this takes a few seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VECTOR_DIMS = len(emb_model.embed_query(\"test\"))\n\nindex_specs = [\n    (\"inst_embedding_idx\", \"Institution\", \"embedding\"),\n    (\"area_embedding_idx\", \"ResearchArea\", \"embedding\"),\n    (\"res_embedding_idx\", \"Researcher\", \"embedding\"),\n    (\"proj_embedding_idx\", \"Project\", \"embedding\"),\n]\n\nwith driver.session() as s:\n    for name, label, prop in index_specs:\n        s.run(f\"\"\"\n        CREATE VECTOR INDEX {name} IF NOT EXISTS\n        FOR (n:{label}) ON (n.{prop})\n        OPTIONS {{ indexConfig: {{\n            `vector.dimensions`: {VECTOR_DIMS},\n            `vector.similarity_function`: 'cosine'\n        }} }}\n        \"\"\")\n    print(\"Indexes created. Waiting for them to come online...\")\n    s.run(\"CALL db.awaitIndexes()\")\n    print(\"Indexes online.\")\n\nwith driver.session() as s:\n    print(\"Existing indexes:\")\n    for rec in s.run(\"SHOW INDEXES YIELD name, type, entityType, labelsOrTypes, properties RETURN *\").data():\n        print(rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure LangChain Vector Stores\n\nHere we configure LangChain Neo4j vector stores for each label. We specify node\\_properties to make sure metadata is returned in search results for filtering and display. This is important, otherwise you just get IDs back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Neo4jVector\n\ninst_vs = Neo4jVector.from_existing_index(\n    embedding=emb_model,\n    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD,\n    index_name=\"inst_embedding_idx\",\n    node_label=\"Institution\",\n    text_node_property=\"name\",\n    embedding_node_property=\"embedding\",\n    retrieval_query=\"RETURN node.name AS text, score, node {.name, .institution_type, .location} AS metadata\"\n)\n\narea_vs = Neo4jVector.from_existing_index(\n    embedding=emb_model,\n    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD,\n    index_name=\"area_embedding_idx\",\n    node_label=\"ResearchArea\",\n    text_node_property=\"description\",\n    embedding_node_property=\"embedding\",\n    retrieval_query=\"RETURN node.description AS text, score, node {.name, .description} AS metadata\"\n)\n\nres_vs = Neo4jVector.from_existing_index(\n    embedding=emb_model,\n    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD,\n    index_name=\"res_embedding_idx\",\n    node_label=\"Researcher\",\n    text_node_property=\"expertise\",\n    embedding_node_property=\"embedding\",\n    retrieval_query=\"RETURN node.expertise AS text, score, node {.name, .title, .expertise} AS metadata\"\n)\n\nproj_vs = Neo4jVector.from_existing_index(\n    embedding=emb_model,\n    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD,\n    index_name=\"proj_embedding_idx\",\n    node_label=\"Project\",\n    text_node_property=\"description\",\n    embedding_node_property=\"embedding\",\n    retrieval_query=\"RETURN node.description AS text, score, node {.title, .description, .host_institution_type, .year} AS metadata\"\n)\n\nprint(\"Vector stores configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieval Strategies\n\n### Strategy 1: Semantic Search for Researchers\n\nUse this when you need to find researchers whose expertise matches a query semantically. Pretty straightforward.\n\nThis searches for researchers whose expertise is semantically similar to the query using vector similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_similar_researchers(query, k=5):\n    docs = res_vs.similarity_search(query, k=k)\n    return [(d.metadata.get(\"name\"), d.page_content) for d in docs]\n\nprint(find_similar_researchers(\"graph neural networks for healthcare\", k=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy 2: Graph\\-Aware Retrieval from Institutions\n\nUse this when you need to find researchers and projects affiliated with institutions matching a query. This adds organizational context you wouldn't get otherwise. I find this particularly useful when looking for collaborative opportunities.\n\nIt starts with vector\\-matched institutions, then traverses the graph to retrieve affiliated researchers and projects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def graph_aware_from_institution(query, k_inst=3, k_proj=5):\n    inst_docs = inst_vs.similarity_search(query, k=k_inst)\n    inst_names = [d.metadata.get(\"name\") for d in inst_docs]\n    cypher = \"\"\"\n    MATCH (i:Institution)<-[:AFFILIATED_WITH]-(r:Researcher)-[:WORKS_ON]->(p:Project)\n    WHERE i.name IN $inst_names\n    WITH i, r, p\n    RETURN i.name AS institution, r.name AS researcher, p.title AS project, p.description AS description\n    LIMIT $limit\n    \"\"\"\n    with driver.session() as s:\n        rows = s.run(cypher, inst_names=inst_names, limit=k_proj*3).data()\n    return rows\n\nprint(graph_aware_from_institution(\"top research in policy and governance\", 3, 6)[:6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy 3: Cross\\-Label Semantic Search\n\nUse this when you need to unify concepts across researchers and projects to find both people and work relevant to a query. Sometimes you don't know if you're looking for a person or a project, right?\n\nThis searches for both researchers and projects semantically similar to the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_label_search(query, k_each=5):\n    r_docs = res_vs.similarity_search(query, k=k_each)\n    p_docs = proj_vs.similarity_search(query, k=k_each)\n    results = {\n        \"researchers\": [(d.metadata.get(\"name\"), d.page_content) for d in r_docs],\n        \"projects\": [(d.metadata.get(\"title\"), d.page_content) for d in p_docs],\n    }\n    return results\n\nprint(cross_label_search(\"retrieval augmented generation evaluation\", 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy 4: Topic Expansion via Research Areas\n\nUse this when you need to expand a query to related topics for broader recall. Actually, this one surprised me with how well it works.\n\nIt finds research areas semantically similar to the query for topic expansion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def expand_topics(query, k=5):\n    areas = area_vs.similarity_search(query, k=k)\n    return [(d.metadata.get(\"name\"), d.page_content) for d in areas]\n\nprint(expand_topics(\"AI policy and governance\", 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy 5: Collaborator Recommendations\n\nUse this when you need to recommend new collaborators for a researcher based on semantic similarity and graph constraints (no shared projects). This is actually really useful for finding potential collaborations.\n\nThe cell recommends collaborators who are semantically similar but don't already share a project with the seed researcher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommend_collaborators(seed_researcher_name, k_sim=10, topn=5):\n    with driver.session() as s:\n        seed = s.run(\"\"\"\n          MATCH (r:Researcher {name:$name})\n          RETURN r.expertise AS expertise\n        \"\"\", name=seed_researcher_name).single()\n    if not seed:\n        return []\n    sim = res_vs.similarity_search(seed[\"expertise\"], k=k_sim)\n    sim_names = [d.metadata.get(\"name\") for d in sim if d.metadata.get(\"name\") != seed_researcher_name]\n    with driver.session() as s:\n        rows = s.run(\"\"\"\n        MATCH (seed:Researcher {name:$seed})\n        MATCH (cand:Researcher)\n        WHERE cand.name IN $cands\n        AND NOT (seed)-[:WORKS_ON]->(:Project)<-[:WORKS_ON]-(cand)\n        RETURN cand.name AS candidate\n        LIMIT $topn\n        \"\"\", seed=seed_researcher_name, cands=sim_names, topn=topn).data()\n    return [r[\"candidate\"] for r in rows]\n\nprint(recommend_collaborators(\"Researcher 1\", k_sim=15, topn=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy 6: Hybrid Filtered Search\n\nUse this when you need to combine semantic similarity with property\\-level filters (like institution type) for targeted retrieval. I use this a lot when I need very specific results.\n\nThis searches for projects semantically similar to the query, filtered by institution type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_projects_filtered(query, institution_type=\"academic\", k=5):\n    docs = proj_vs.similarity_search(query, k=k, filter={\"host_institution_type\": institution_type})\n    return [(d.metadata.get(\"title\"), d.page_content, d.metadata.get(\"host_institution_type\")) for d in docs]\n\nprint(search_projects_filtered(\"AI policy and governance\", \"academic\", 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run All Strategies and Validate\n\nFinally, let's run all six retrieval strategies and print results for validation. This gives you a good sense of what each strategy returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n1) Semantic researchers:\")\nprint(find_similar_researchers(\"graph neural networks for healthcare\", 5))\n\nprint(\"\\n2) Graph-aware from institution:\")\nprint(graph_aware_from_institution(\"policy governance research organizations\", 3, 6)[:6])\n\nprint(\"\\n3) Cross-label search:\")\nprint(cross_label_search(\"retrieval augmented generation evaluation\", 5))\n\nprint(\"\\n4) Topic expansion:\")\nprint(expand_topics(\"AI policy and governance\", 5))\n\nprint(\"\\n5) Collaboration recommendations:\")\nprint(recommend_collaborators(\"Researcher 3\", 15, 5))\n\nprint(\"\\n6) Hybrid filtered projects:\")\nprint(search_projects_filtered(\"AI policy and governance\", \"academic\", 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n\nAlright, so you now have a working Knowledge Graph RAG pipeline. To extend it, here's what I'd suggest:\n\n* **Integrate into a RAG chain**: Wrap these retrieval strategies in LangChain chains and pass results to an LLM for generation. This is where it gets really powerful.\n* **Add re\\-ranking and path scoring**: Use cross\\-encoders or custom scoring to rank results by relevance and relationship strength. I've experimented with this and it makes a big difference.\n* **Scale and operationalize**: Deploy Neo4j on managed infrastructure, add monitoring, and optimize embedding batch sizes for production workloads. The batch size optimization alone can save you a lot of time and money."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build a Knowledge Graph RAG Pipeline with Neo4j + Embeddings",
    "description": "A comprehensive, hands-on tutorial that walks developers through building a complete Knowledge Graph RAG system using Neo4j, LangChain, and OpenAI embeddings. Learn to model entities and relationships, generate semantic embeddings, and implement six powerful query strategies that boost recall, reduce hallucinations, and deliver contextually rich answers. This practical guide includes fully executable Python code, real dataset examples, and step-by-step implementation from setup to validation.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}