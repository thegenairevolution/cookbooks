{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build an LLM Agent from Scratch with GPT-4 ReAct\n\n**Description:** Build a fully functional LLM agent in Python using ReAct, tool actions, regex parsing, and GPT-4, automated control loop included.\n\n**ðŸ“– Read the full article:** [How to Build an LLM Agent from Scratch with GPT-4 ReAct](https://blog.thegenairevolution.com/article/how-to-build-an-llm-agent-from-scratch-with-gpt-4-react-2)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You probably use agent frameworks like LangChain or BabyAGI without really seeing how they work under the hood. Here's the thing \\- this tutorial is your chance to peel back those layers. We're going to build a ReAct\\-style agent from scratch, no frameworks, no magic. When you see how each part actually works, you'll understand what those frameworks are really doing for you.\n\nThe whole approach comes from this paper \"[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)\" (arXiv:2210\\.03629\\) by Yao et al. What they discovered was pretty straightforward but powerful: you get better performance and interpretability when a model both reasons (writes out its thoughts) and acts (calls tools), weaving those steps together with observations.\n\n![Uploaded image](/public-objects/user_insert_44830763_1762007676886.png \"Uploaded image\")\n\n## Why This Approach Works\n\nLook, frameworks are convenientâ€”I get it. But they hide so much behavior. When I first started building agents from scratch, I realized how much control you actually gain. Debugging becomes faster. You know exactly when and why the model does something, not just that it did something. Youâ€™ll then be better equipped to use the frameworks with confidence.\n\n**Why GPT\\-4o and GPT\\-4o\\-mini?** GPT\\-4o gives you strong reasoning for the main agent loop. GPT\\-4o\\-mini handles simple tool lookups cheaply and quickly. Honestly, this combination keeps costs reasonable without losing reliability. I've tried other setups, and this balance just works.\n\n**Why ReAct?** The ReAct pattern forces the model to articulate its reasoning before taking action. That makes everything interpretable. You can actually see what it's thinking. The strict formatâ€”Thought â†’ Action â†’ PAUSE â†’ Observationâ€”lets you parse and validate every step programmatically. No guessing games.\n\n**Why regex parsing?** Okay, I know what you're thinking. Regex in 2024? But here's why: it's deterministic, fast, and completely transparent. You know exactly what matches and what doesn't. Sure, for production you might swap in JSON\\-based arguments or the OpenAI function\\-call API. But regex is the simplest way to start and actually understand what's happening.\n\n## How It Works (High\\-Level Overview)\n\nLet me walk you through what actually happens:\n\n1. Your agent receives a question, then generates a Thought and an Action. Something like: lookup\\_distance\\[Montreal, Boston].\n2. The control loop parses that Action using regex, validates it, and calls the corresponding Python function.\n3. The tool returns a result (maybe \"308 miles\"), which becomes the Observation.\n4. Now the agent updates its reasoning with this new info. It either calls another tool or gives you a final Answer.\n5. The loop stops once the agent outputs Answer: or hits the max turn limit. That last part is crucial \\- you don't want runaway agents eating up your API credits.\n\n## Setup \\& Installation\n\nRun this cell in Colab or your local environment to install dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your OpenAI API key. In Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # Replace with your key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or if you're working locally, create a .env file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=sk-..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actually, before you do anything else, verify the key is set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nif not os.getenv(\"OPENAI_API_KEY\"):\n    raise EnvironmentError(\"OPENAI_API_KEY not set. Please set it before running.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step\\-by\\-Step Implementation\n\n### Define the System Prompt\n\nThis is basically the contract between you and the model. It enforces the ReAct format and lists available actions with their exact signatures. Get this wrong, and nothing else will work properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"\nYou operate in a structured loop consisting of Thought, Action, PAUSE, and Observation.\nAt the end of the loop, you output an Answer. Follow this process to reason through questions and perform actions to provide accurate results.\n\nProcess Breakdown:\n1. Thought: Think through the question and explain your reasoning about the next action to take.\n2. Action: Use one of the available actions to gather information or perform calculations. Follow the correct syntax for the action. End with PAUSE after specifying the action.\n3. Observation: Review the result of the action and decide the next step. Continue the loop as needed until the question is fully resolved.\n4. Answer: Once all steps are complete, provide a clear and concise response.\n\nAvailable Actions:\n- lookup_distance:\n  e.g., lookup_distance: Toronto to Montreal\n  Finds the driving distance between two locations in kilometers.\n\n- calculate_travel_time:\n  e.g., calculate_travel_time: 540 km at 100 km/h\n  Calculates the travel time for a given distance at the specified average speed.\n\n- calculate_sum:\n  e.g., calculate_sum: 3.88 hours + 5.54 hours\n  Sums two values with units (e.g., hours or kilometers) and returns the total.\n\nExample Session:\nQuestion: How long will it take to drive from Toronto to Montreal if I travel at an average speed of 110 km/h?\n\nThought: I first need to find the driving distance between Toronto and Montreal using the lookup_distance action.\nAction: lookup_distance: Toronto to Montreal\nPAUSE\n\nObservation: The driving distance between Toronto and Montreal is 541 kilometers.\n\nThought: Now, I need to calculate the travel time for 541 kilometers at an average speed of 110 km/h using the calculate_travel_time action.\nAction: calculate_travel_time: 541 km at 110 km/h\nPAUSE\n\nObservation: The travel time is approximately 4.92 hours.\n\nAnswer: The drive from Toronto to Montreal will take approximately 4.92 hours if you travel at an average speed of 110 km/h.\n\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build the Agent Class\n\nThe Agent class manages your conversation history. It makes calls to the OpenAI API and keeps track of messages so the model has full context each turn. Pretty straightforward stuff, but essential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nimport logging\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict\nfrom openai import OpenAI\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n@dataclass\nclass Agent:\n    system_prompt: str\n    model: str = \"gpt-4o\"\n    temperature: float = 0.0\n    messages: List[Dict[str, str]] = field(default_factory=list)\n\n    def __post_init__(self):\n        self.messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n\n    def __call__(self, user_content: str) -> str:\n        self.messages.append({\"role\": \"user\", \"content\": user_content})\n        return self.execute()\n\n    def execute(self) -> str:\n        resp = client.chat.completions.create(\n            model=self.model,\n            temperature=self.temperature,\n            messages=self.messages,\n        )\n        content = resp.choices[0].message.content\n        self.messages.append({\"role\": \"assistant\", \"content\": content})\n        logger.debug(f\"Assistant: {content}\")\n        return content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implement the Tools\n\nEach tool is just a simple Python function. Now, the distance lookup uses an LLM call for realism \\- I know that might seem weird, but you can swap in deterministic maps or real APIs later. The point is to show the pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n\ndef generate_response(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n    # Helper function to generate a simple response from a smaller model\n    resp = client.chat.completions.create(\n        model=model,\n        temperature=0,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Reply with the answer only.\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ],\n    )\n    return resp.choices[0].message.content.strip()\n\ndef lookup_distance(prompt: str) -> str:\n    # Tool to find the driving distance between two locations using an LLM call\n    gpt_prompt = f\"Find the driving distance in kilometers between {prompt}. Return the result as a single sentence.\"\n    return generate_response(gpt_prompt)\n\ndef _extract_number(s: str) -> float:\n    # Helper to extract a number from a string\n    m = re.search(r\"(-?[0-9]+(?:\\.[0-9]+)?)\", s)\n    if not m:\n        raise ValueError(f\"Cannot parse number from: {s}\")\n    return float(m.group(1))\n\ndef calculate_travel_time(distance: str, speed: str) -> str:\n    # Tool to calculate travel time given distance and speed\n    d = _extract_number(distance)\n    v = _extract_number(speed)\n    if v == 0:\n        return \"infinite hours\"\n    hours = d / v\n    return f\"{round(hours, 2)} hours\"\n\ndef _extract_number_and_unit(s: str) -> (float, str):\n    # Helper to extract number and unit from a string\n    m = re.search(r\"(-?[0-9]+(?:\\.[0-9]+)?)\\\\s*([a-zA-Z/%]+)?\", s.strip())\n    if not m:\n        raise ValueError(f\"Cannot parse: {s}\")\n    value = float(m.group(1))\n    unit = m.group(2) or \"\"\n    return value, unit\n\ndef calculate_sum(value1: str, value2: str) -> str:\n    # Tool to sum two values with units\n    v1, u1 = _extract_number_and_unit(value1)\n    v2, u2 = _extract_number_and_unit(value2)\n    # Use the unit if both values have the same unit\n    unit = u1 if u1 == u2 else \"\"\n    total = v1 + v2\n    return f\"{round(total, 2)}{(' ' + unit) if unit else ''}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Register Tools and Define Parsers\n\nHere we set up a registry for dispatch. The regex patterns parse the agent's output into actions or answers. This is where that transparency I mentioned earlier really pays off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional, List, Tuple\nimport re\n\n# Register available actions with their corresponding functions\nKNOWN_ACTIONS = {\n    \"lookup_distance\": lookup_distance,\n    \"calculate_travel_time\": calculate_travel_time,\n    \"calculate_sum\": calculate_sum,\n}\n\ndef parse_action(text: str) -> Optional[Tuple[str, List[str]]]:\n    # Parse the agent's output to find an action line\n    action_line = None\n    for line in text.splitlines():\n        if line.strip().lower().startswith(\"action:\"):\n            action_line = line.strip()\n            break\n\n    if not action_line:\n        return None\n\n    # Extract action name and parameters\n    action_text = action_line[len(\"action:\"):].strip()\n    action_parts = action_text.split(\":\", 1)\n\n    if len(action_parts) < 2:\n         return None\n\n    name = action_parts[0].strip()\n    raw_params = action_parts[1].strip()\n\n    # Custom parsing for calculate_travel_time due to its parameter format\n    if name == \"calculate_travel_time\":\n        parts = raw_params.split(\" at \")\n        if len(parts) == 2:\n            params = [parts[0].strip(), parts[1].strip()]\n        else:\n            # Handle cases where calculate_travel_time parameters are not as expected\n            return None\n    else:\n        # Default comma splitting for other action parameters\n        params = [p.strip().strip('\"').strip(\"'\") for p in raw_params.split(\",\")] if raw_params else []\n\n    return name, params\n\ndef parse_answer(text: str) -> Optional[str]:\n    # Parse the agent's output to find the final answer line\n    answer_line = None\n    for line in text.splitlines():\n        if line.strip().lower().startswith(\"answer:\"):\n            answer_line = line.strip()\n            break\n\n    if not answer_line:\n        return None\n\n    # Extract the answer text\n    answer_text = answer_line[len(\"answer:\"):].strip()\n    return answer_text\n\n\ndef validate_action(name: str, params: List[str]) -> bool:\n    # Validate if the parsed action is a known action\n    if name not in KNOWN_ACTIONS:\n        raise ValueError(f\"Unknown action: {name}\")\n    # Optional: Add more specific parameter validation here if needed\n    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build the Control Loop\n\nThis is where the magic happens. The loop goes through thinking, acting, and observing until you get a final answer or hit a turn limit. That turn limit? Super important. Trust me, you don't want runaway agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_agent_loop(question: str, max_turns: int = 10, verbose: bool = True) -> str:\n    # Initialize the agent with the system prompt\n    agent = Agent(system_prompt=SYSTEM_PROMPT, model=\"gpt-4o\", temperature=0)\n    # Send the initial question to the agent\n    last = agent(question)\n\n    if verbose:\n        print(\"TURN 1 - ASSISTANT\\n\", last, \"\\n\")\n\n    turn = 1\n    # Start the agent loop\n    while turn < max_turns:\n        # Attempt to parse the final answer\n        answer = parse_answer(last)\n        if answer:\n            # If an answer is found, print and return it\n            if verbose:\n                print(\"FINAL ANSWER\\n\", answer)\n            return answer\n\n        # If no answer, attempt to parse an action\n        parsed = parse_action(last)\n        if not parsed:\n            # If no action or answer is found, stop the loop\n            if verbose:\n                print(\"No action or answer detected. Stopping.\")\n            return \"Unable to complete: no action or answer detected.\"\n\n        # Extract action name and parameters\n        name, params = parsed\n        try:\n            # Validate the action and execute the corresponding tool\n            validate_action(name, params)\n            tool = KNOWN_ACTIONS[name]\n            result = tool(*params)\n        except Exception as e:\n            # Handle any errors during tool execution\n            result = f\"ERROR: {str(e)}\"\n\n        # Format the tool result as an observation\n        obs_msg = f\"Observation: {result}\"\n        turn += 1\n        # Send the observation back to the agent for the next turn\n        last = agent(obs_msg)\n\n        if verbose:\n            print(f\"TURN {turn} - OBSERVATION\\n\", obs_msg)\n            print(f\"TURN {turn} - ASSISTANT\\n\", last, \"\\n\")\n\n    # If the maximum number of turns is reached without finding an answer\n    if verbose:\n        print(\"Max turns reached without final answer.\")\n    return \"Unable to complete within turn limit.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run and Validate\n\nLet's test the agent with a multi\\-step question that requires two tool calls: distance lookup, then travel time calculation. This is where you see if everything actually works together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n    print(run_agent_loop(\"How long to drive from Montreal to Boston at 60 mph?\", max_turns=8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected output:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TURN 1 - ASSISTANT\nThought: I need to find the distance from Montreal to Boston first.\nAction: lookup_distance[Montreal, Boston]\nPAUSE\n\nTURN 2 - OBSERVATION\n..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connecting Back to ReAct (the Paper)\n\nSo what does \"ReAct: Synergizing Reasoning and Acting in Language Models\" actually teach us? And how did it shape this tutorial?\n\nThe paper shows that when you interleave reasoning and action, you get much more robust behavior. Makes sense when you think about it \\- reasoning lets the model plan, actions let it get grounded information, and observations let it correct and update what it thought. It's like... actually, it's exactly like how we solve problems ourselves.\n\nWhat's interesting is that ReAct outperformed both reasoning\\-only approaches (Chain\\-of\\-Thought) and acting\\-only approaches on tasks like HotpotQA and FEVER. It reduces hallucinations and error propagation by using external sources. The model can't just make stuff up when it has to check with tools.\n\nThe format we're using here is basically identical: Thought â†’ Action â†’ Observation â†’ Thought â†’ â€¦ â†’ Answer. That gives you both interpretability and control. You can see exactly where things go wrong if they do.\n\nAnd here's the thing \\- if you look at the frameworks you already use, they adopt very similar contracts. They make you define tool signatures, control loops, stopping criteria, all of it. This tutorial reproduces those pieces explicitly so you can actually see them working.\n\nYou're now set up to experiment. Add more tools, tweak the formats, change the logic \\- whatever you want. Doing this by hand teaches you what the frameworks automate. And honestly? That knowledge will make you a better builder and a much better debugger. When something goes wrong (and it will), you'll know exactly where to look."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build an LLM Agent from Scratch with GPT-4 ReAct",
    "description": "Build a fully functional LLM agent in Python using ReAct, tool actions, regex parsing, and GPT-4, automated control loop included.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}