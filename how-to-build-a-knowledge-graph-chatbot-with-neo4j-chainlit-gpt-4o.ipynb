{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o\n\n**Description:** Ship a Python knowledge graph chatbot using Neo4j, Chainlit, and GPT-4oâ€”auto-generate Cypher, visualize results, and answer complex data questions accurately.\n\n**ðŸ“– Read the full article:** [How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o](https://blog.thegenairevolution.com/article/how-to-build-a-knowledge-graph-chatbot-with-neo4j-chainlit-gpt-4o-3)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In an earlier post, we went through [how to build a knowledge graph using Neo4j](/article/how-to-build-a-knowledge-graph-rag-pipeline-with-neo4j-embeddings-2) and add semantic search capabilities to really boost a retrieval\\-augmented generation (RAG) pipeline. We looked at extracting structured entities and relationships from messy unstructured content, getting everything into a graph database, and then doing hybrid retrieval with both vector embeddings and graph queries. If you want to dig deeper into making retrieval work better, check out our guide on [retrieval tricks to boost answer accuracy in RAG pipelines](/article/rag-application-7-retrieval-tricks-to-boost-answer-accuracy-2).\n\nHere's what I've discovered about knowledge graphs and large language models like GPT\\-4o. They actually complement each other really well. I was honestly surprised at how good these models are at turning natural language into Cypher queries. And when you give them a clear picture of your graph schema, with all the nodes and relationships laid out, they can reason through it pretty effectively. What this means for you is that you can literally ask questions about your data in plain English, and the model just... gets it. It translates your question into these powerful graph queries almost without thinking about it. If you're thinking about expanding to handle multiple documents and more advanced retrieval, our guide on [building multi\\-document agents for advanced retrieval and summarization](/article/multi-document-agent-with-llamaindex-the-ultimate-guide-2025-2) has everything you need to know.\n\n![Uploaded image](/public-objects/user_insert_44830763_1763667388200.png \"Uploaded image\")\n\nSo let's take this to the next level. I'm going to show you how to build an interactive chatbot interface using Chainlit and GPT\\-4o that lets you have actual conversations with your graph database. We'll pass in conversation history, format the knowledge graph context so the LLM understands it properly, pull out the Cypher from the response, run the query, and then return results as both natural language answers and visual charts. By the time we're done, you'll have a fully working conversational interface for your Neo4j knowledge graph.\n\n## Setup\n\nFirst, let's get the required packages installed. Just run this command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install neomodel chainlit plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Configure Neomodel and Test Your Neo4j Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile setup.py\n\nimport os\nfrom neomodel import db, config\n\n#load your API key safely:\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\n# Extract components\nuri = os.getenv(\"NEO4J_URI\")          \nuser = os.getenv(\"NEO4J_USERNAME\")     \npassword = os.getenv(\"NEO4J_PASSWORD\") \n\nif not all([uri, user, password]):\n    raise ValueError(\"Missing one or more of: NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD\")\n\n# Convert neo4j+s:// to bolt+s:// for Neomodel\nhost = uri.replace(\"neo4j+s://\", \"\")\nbolt_url = f\"bolt+s://{user}:{password}@{host}\"\nconfig.DATABASE_URL = bolt_url\n\n# Test the connection\ntry:\n    results, _ = db.cypher_query(\"RETURN 'Connection successful' AS message\")\n    print(results[0][0])\nexcept Exception as e:\n    print(f\"Connection failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create the Tool\n\nNow we need to build the tool that lets us query our knowledge graph. It's going to take natural language input, figure out the right Cypher query, run it against the Neo4j database, and give us back the results. Actually, if you're interested in learning more about designing tools for agent frameworks, you should definitely look at our guide on [how to build flexible tools for CrewAI agents](/article/how-to-build-flexible-tools-for-crewai-agents-2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile tools/query_knowledge_graph.py\n\nfrom setup import *\nfrom crewai.tools import tool\n\n@tool\ndef query_knowledge_graph(query: str):\n    \"Query the Neo4j Knowledge Graph\"\n    results, meta = db.cypher_query(query)\n    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the Tool\n\nAlright, with the tool ready to go, let's test it out by running a sample query against our knowledge graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tools.query_knowledge_graph import query_knowledge_graph\n\n# Test it\nquery = \"\"\"\nMATCH (n)\nWITH labels(n) AS lbls\nUNWIND lbls AS label\nRETURN label, count(*) AS count\nORDER BY count DESC;\n\"\"\"\nprint(query_knowledge_graph.run(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Using Tool: query_knowledge_graph\n[['Researcher', 157], ['Project', 46], ['ResearchArea', 20], ['Institution', 20]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Your Agent\n\nTime to set up the agent and its tasks using the standard CrewAI format. This agent is going to be responsible for understanding what users are asking and generating the right Cypher queries to pull data from the knowledge graph. If you want to see how this fits into bigger multi\\-agent systems and more complex workflows, take a look at our [practical lessons from building multi\\-agent systems with CrewAI and LangChain](/article/practical-lessons-from-building-multi-agent-systems-with-crewai-and-langchain).\n\n### Create the agents.yaml file\n\nWhen I was designing the agent prompt, I had a few specific strategies in mind to make sure the LLM would work effectively. Let me walk you through what actually worked:\n\n* **Expertise framing**: We tell the agent it's an expert analyst who knows Neo4j inside and out and can explain results clearly.\n\n* **Resilience**: The agent doesn't give up. If a query doesn't work, it tries different approaches until it finds the data.\n\n* **Polite tone**: Every response needs to be courteous, professional, and actually helpful to the user.\n\n* **Cypher guidance**: This one's important. We specifically tell it to use WITH instead of SQL\\-style GROUP BY to avoid common mistakes.\n\n* **Schema awareness**: We give it the complete graph structure, all the nodes, properties, relationships, everything. That way it can generate accurate Cypher queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile config/agents.yaml\n\ngraph_analyst:\n  role: >\n    Knowledge Graph Analyst\n  goal: >\n    Answer user questions with precise, grounded insights by querying structured data from a knowledge graph.\n  backstory: >\n    <expertise>\n        You're an expert analyst trained in interpreting user questions, retrieving information from a Neo4j\n        knowledge graph, and delivering clear, well-structured answers. You bridge human language with\n        graph-based reasoning to produce reliable insights grounded in real data.\n    </expertise>\n    \n    <tenacity>\n        You are tenacious when retrieving information from a Neo4j. If the query yields no results, you DO NOT give up and say that nothing was found.  \n        Instead, you must rethink the question, try alternative keywords, adjust filters, explore related entity types, or reframe the query entirely.  \n        Retry as many times as necessary until you find a meaningful result.\n    </tenacity>\n    \n    <tone>\n        You always respond in a polite, helpful, and courteous manner. Your tone is respectful, professional, and friendly, ensuring the user feels supported and understood.\n    </tone>\n    \n    <cypher_guidance>\n        Do not use SQL syntax like GROUP BY in Cypher. Instead, use the WITH clause to group data before returning it.\n        Example:\n        Use:\n          WITH YEAR(p.start_date) AS year, COUNT(*) AS count\n          RETURN year, count\n        Not:\n          RETURN YEAR(p.start_date), COUNT(*) GROUP BY YEAR(p.start_date)\n    </cypher_guidance>\n    \n    <schema>\n    <node name=\"Institution\">\n      Represents universities or organizations. Properties include:\n      - name (string, required, unique): Name of the institution\n      - type (string): Type of institution\n      - address (string): Address of the institution\n      - context (string): Additional contextual info\n    </node>\n    \n    <node name=\"Researcher\">\n      Represents individuals working on projects. Properties include:\n      - name (string, required): Name of the researcher\n      - role (string): Their role in the project\n      - specialization (string): Their expertise\n      - commitment_percent (int): Level of involvement\n      - honorarium_amount (float): Payment amount\n      - honorarium_currency (string): Currency type\n      - honorarium_frequency (string): Payment frequency\n      - Relationships:\n        - AFFILIATED_WITH â†’ Institution\n    </node>\n    \n    <node name=\"ResearchArea\">\n      Represents a field or topic of research. Properties:\n      - name (string, required, unique)\n    </node>\n    \n    <node name=\"Project\">\n      Represents research projects. Properties include:\n      - file_name (string, required, unique): Unique identifier for the project\n      - type (string): Type of project\n      - summary_description (string): Project summary\n      - start_date, end_date (string): Project duration\n      - Relationships:\n        - HAS_PARTICIPANT â†’ Institution\n        - HAS_RESEARCHER â†’ Researcher\n        - COVERS_TOPIC â†’ ResearchArea\n    </node>\n    </schema>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the tasks.yaml file\n\nTo make sure the LLM gives accurate, respectful answers with helpful visualizations, I built the task prompt with these strategies:\n\n* **Contextual grounding**: We include the entire conversation history plus the latest user input. This lets the agent maintain continuity and reuse previous context when it makes sense.\n\n* **Smart query planning**: The LLM uses history or metadata whenever possible. It only queries Neo4j when it actually needs to.\n\n* **Cypher correctness**: We give it specific guidance to avoid syntax errors, especially around WITH and RETURN ordering. Trust me, this saves a lot of headaches.\n\n* **Persistence**: The agent can't just return empty results. If a query fails, it has to try again with a different approach.\n\n* **Polished communication**: Responses need to be clear, concise, and always courteous.\n\n* **Visual output**: When it makes sense, the agent creates charts, bar graphs, line graphs, pie charts, or markdown tables to make the data easier to understand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile config/tasks.yaml\n\nanswer_user_question:\n  description: |\n    <CONVERSATION_HISTORY>\n    {history}\n    </CONVERSATION_HISTORY>\n\n    <NEW_USER_QUESTION>\n    {input}\n    </NEW_USER_QUESTION>\n\n    <INSTRUCTIONS>\n      <analysis>\n        Carefully analyze the user's question to understand what information is being requested.\n        Identify the relevant entities, relationships, and any applicable filters.\n        Use the metadata and conversation history if it contains sufficient context to answer the question directly.\n        Querying the Neo4j knowledge graph is optional and should only be performed if the answer cannot be fully determined from prior messages.\n      </analysis>\n    \n      <querying>\n        If a query is needed, formulate and execute the appropriate Cypher query against the Neo4j graph to retrieve the necessary data.\n    \n        <cypher_guidance>\n          In Cypher, the `RETURN` clause must always come at the end of the query. \n          You cannot place `RETURN` before a `WITH` clause in the same logical flow.\n    \n          Invalid:\n          MATCH (p:Project)\n          RETURN SUBSTRING(p.start_date, 0, 4) AS year, COUNT(*) AS project_count\n          WITH year, project_count\n          ORDER BY year\n    \n          Correct:\n          MATCH (p:Project)\n          WITH SUBSTRING(p.start_date, 0, 4) AS year, COUNT(*) AS project_count\n          ORDER BY year\n          RETURN year, project_count\n    \n          Always use `WITH` to perform intermediate aggregation or transformation, and only use `RETURN` at the final step of the query.\n        </cypher_guidance>\n      </querying>\n    \n      <requirements>\n        <IMPORTANT>\n          - A Cypher query against the Neo4j graph should ALWAYS retrieve data.  \n          - DO NOT accept or return an empty result.  \n          - If the query yields no results, you DO NOT give up and respond that nothing was found.  \n          - Instead, you must rethink the question, try alternative keywords, adjust filters, explore related entity types, or reframe the query entirely.  \n          - Retry as many times as necessary until you find a meaningful result.\n        </IMPORTANT>\n      </requirements>\n    \n      <response_style>\n        Once data is retrieved, synthesize a concise, well-structured answer in natural language, backed by facts from the graph.  \n        Always present your answer in a courteous, respectful, and helpful tone.\n        Even when correcting a misunderstanding or clarifying limitations, remain friendly and supportive.\n      </response_style>\n    \n      <visualization>\n        If the answer involves numerical comparisons, trends over time, or proportional breakdowns, include a chart.\n    \n        <chart_types>\n          - \"bar\": for categorical comparisons\n          - \"line\": for trends over time\n          - \"pie\": for showing proportions\n        </chart_types>\n    \n        <chart_example type=\"bar\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "json\n          {\n            \"type\": \"bar\",\n            \"labels\": [\"AI\", \"Cybersecurity\", \"Data Science\"],\n            \"values\": [12, 8, 15],\n            \"title\": \"Projects by Research Area\"\n          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "</chart_example>\n    \n        <chart_example type=\"line\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "json\n          {\n            \"type\": \"line\",\n            \"labels\": [\"2019\", \"2020\", \"2021\", \"2022\"],\n            \"values\": [5, 12, 18, 25],\n            \"title\": \"Number of Projects Over Time\"\n          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "</chart_example>\n    \n        <chart_example type=\"pie\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "json\n          {\n            \"type\": \"pie\",\n            \"labels\": [\"Government\", \"Academic\", \"Private\"],\n            \"values\": [30, 45, 25],\n            \"title\": \"Funding Sources by Sector\"\n          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "</chart_example>\n    \n        <markdown_table_guidance>\n          If the result is best represented in tabular form, use a **Markdown table** instead of a chart.\n    \n          Example:\n\n          | Name            | Institution         | Specialization         |\n          |-----------------|---------------------|-------------------------|\n          | Dr. Rachel Liu  | GreenTech Institute | AI for Urban Planning  |\n          | Dr. Nina Feld   | GreenTech Institute | Multilingual NLP       |\n          | Dr. M. Rinaldi  | GreenTech Institute | AI for Education       |\n    \n          Always include clear headers and ensure that the data is aligned and readable.\n            \n        </markdown_table_guidance>\n      </visualization>\n    </INSTRUCTIONS>\n\n\n  expected_output: >\n    A concise, well-structured answer in natural language, backed by data retrieved from the knowledge graph.\n    Include any key entities, metrics, or facts that support the answer.\n    If appropriate, include JSON-encoded chart data inside a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "json code block for visualization.\n  agent: graph_analyst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Create the Crew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n%%writefile crew.py\n\nfrom crewai import Agent, Crew, Task, Process\nfrom crewai.project import CrewBase, agent, task, crew, before_kickoff, after_kickoff\nfrom crewai.agents.agent_builder.base_agent import BaseAgent\nfrom typing import List\nfrom tools.query_knowledge_graph import query_knowledge_graph\n\n@CrewBase\nclass KnowledgeGraphAnsweringCrew:\n    \"\"\"Crew that understands user questions, queries a knowledge graph, and composes grounded answers.\"\"\"\n\n    agents: List[BaseAgent]\n    tasks: List[Task]\n\n    # Paths to YAML configuration files\n    agents_config = 'config/agents.yaml'\n    tasks_config = 'config/tasks.yaml'\n\n    @agent\n    def graph_analyst(self) -> Agent:\n        return Agent(\n            config=self.agents_config['graph_analyst'],\n            verbose=True\n        )\n\n    @task\n    def answer_user_question(self) -> Task:\n        return Task(\n            config=self.tasks_config['answer_user_question'],\n            tools=[query_knowledge_graph]\n        )\n\n    @crew\n    def crew(self) -> Crew:\n        return Crew(\n            agents=self.agents,\n            tasks=self.tasks,\n            process=Process.sequential,\n            verbose=False,\n        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 4: Create Our Chatbot\n\nNow we're ready to bring everything together. In this step, we'll build the actual chatbot interface that connects our agent, the task, and the knowledge graph. This is what lets users ask questions in natural language and get back rich, structured responses that actually make sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n%%writefile chat.py\n\nimport plotly.graph_objects as go\nimport chainlit as cl\nimport json\nimport re\n\nfrom setup import *  # Custom setup (e.g., environment config, API keys)\nfrom crew import KnowledgeGraphAnsweringCrew  # Your CrewAI implementation\n\n# Format conversation history as Markdown for context injection\ndef format_history_as_markdown(history):\n    md = \"\"\n    for msg in history:\n        author = msg[\"author\"].capitalize()\n        content = msg[\"content\"].strip()\n        md += f\"**{author}:** {content}\\n\\n\"\n    return md\n\n# Extract and parse a JSON code block from the reply (if present)\ndef extract_json_and_clean_reply(reply: str):\n    pattern = r\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```json\n(.*?)\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"\n    match = re.search(pattern, reply, re.DOTALL)\n    json_data = None\n\n    if match:\n        json_block = match.group(1).strip()\n        try:\n            json_data = json.loads(json_block)\n        except json.JSONDecodeError:\n            json_data = None\n        # Remove the JSON code block from the reply text\n        reply = reply.replace(match.group(0), \"\").strip()\n\n    return reply, json_data\n\n# Generate a Plotly chart from JSON data (bar, line, pie supported)\ndef generate_plot_from_json(data: dict) -> go.Figure:\n    chart_type = data.get(\"type\", \"\")\n    title = data.get(\"title\") or f\"{chart_type.capitalize()} Chart\"\n\n    if chart_type == \"bar\":\n        fig = go.Figure(data=[\n            go.Bar(x=data.get(\"labels\", []), y=data.get(\"values\", []))\n        ])\n    elif chart_type == \"line\":\n        fig = go.Figure(data=[\n            go.Scatter(x=data.get(\"labels\", []), y=data.get(\"values\", []), mode=\"lines\")\n        ])\n    elif chart_type == \"pie\":\n        fig = go.Figure(data=[\n            go.Pie(labels=data.get(\"labels\", []), values=data.get(\"values\", []))\n        ])\n    else:\n        print(f\"[WARN] Unsupported chart type: {chart_type}\")\n        fig = go.Figure()\n\n    return fig\n\n# Chainlit message handler for incoming user messages\n@cl.on_message\nasync def on_message(message: cl.Message):\n    # Retrieve previous conversation history from session\n    history = cl.user_session.get(\"history\") or []\n\n    # Instantiate and prepare the Crew\n    crew_base = KnowledgeGraphAnsweringCrew()\n    crew = crew_base.crew()\n\n    # Package user input and formatted history for the agent\n    user_input = {\n        \"input\": message.content,\n        \"history\": format_history_as_markdown(history)\n    }\n\n    # Run the Crew to process the message\n    result = await cl.make_async(crew.kickoff)(inputs=user_input)\n    reply = result.raw_output if hasattr(result, \"raw_output\") else str(result)\n\n    # Extract JSON data (if any) and remove it from the visible reply\n    reply_no_code, chart_data = extract_json_and_clean_reply(reply)\n\n    # Update conversation history\n    history.append({\"author\": \"user\", \"content\": message.content})\n    history.append({\"author\": \"assistant\", \"content\": reply})\n    cl.user_session.set(\"history\", history)\n\n    # If a valid chart type is found, display it inline with the message\n    if chart_data and chart_data.get(\"type\") in {\"bar\", \"line\", \"pie\"}:\n        fig = generate_plot_from_json(chart_data)\n        await cl.Message(\n            content=reply_no_code,\n            elements=[cl.Plotly(name=\"chart\", figure=fig, display=\"inline\")]\n        ).send()\n    else:\n        # If no chart is detected, just send the full reply as-is\n        await cl.Message(content=reply).send()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Run the App\n\nTo get the chatbot running, just use this command. It starts up the Chainlit server and makes your chatbot available at <http://localhost:8000>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n!chainlit run chat.py --host 0.0.0.0 --port 8000\n```\n\n\n![Uploaded image](/public-objects/user_insert_44830763_1763666603455.png \"Uploaded image\")\n\n## Conclusion\n\nWorking with relational data using LLMs can be really challenging. You've got multiple tables, complex relationships everywhere. And while large language models can theoretically generate SQL, in practice? They often struggle to consistently produce queries that actually work. I've run into this problem more times than I can count in various projects.\n\nNeo4j and knowledge graphs offer a really powerful alternative. Even when you have a complex schema with tons of different node types and relationships, LLMs like GPT\\-4o are surprisingly good at generating correct Cypher queries. And they do it consistently. Actually, the more I think about it, combining this with semantic search gives you the best of both worlds. You get all the flexibility of a vector database plus the structured querying power of a relational database. And it's all wrapped up in a conversational interface that anyone can use.\n\nIf you want to make your chatbot even more effective, consider using [in\\-context learning techniques to improve LLM responses](/article/the-magic-of-in-context-learning-teach-your-llm-on-the-fly-3)."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o",
    "description": "Ship a Python knowledge graph chatbot using Neo4j, Chainlit, and GPT-4oâ€”auto-generate Cypher, visualize results, and answer complex data questions accurately.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}