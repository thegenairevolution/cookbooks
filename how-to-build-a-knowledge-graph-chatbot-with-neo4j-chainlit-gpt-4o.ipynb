{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o\n\n**Description:** Ship a Python knowledge graph chatbot using Neo4j, Chainlit, and GPT-4oâ€”auto-generate Cypher, visualize results, and answer complex data questions accurately.\n\n**ðŸ“– Read the full article:** [How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o](https://blog.thegenairevolution.com/article/how-to-build-a-knowledge-graph-chatbot-with-neo4j-chainlit-gpt-4o)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to the Build\n\nKnowledge graphs are fantastic at modeling complex relationships, but here's the problem: querying them requires Cypher, and that's a real barrier for non\\-technical users. So I decided to build something that would solve this \\- a production\\-ready chatbot that takes natural language questions, converts them into Cypher queries, runs them against Neo4j, and returns both tabular results and interactive visualizations.\n\nWhat you'll be building here combines GPT\\-4o for query generation, Neo4j for graph storage, CrewAI for agent orchestration, and Chainlit for the conversational UI. By the time you're done, you'll have a working system that handles multi\\-hop reasoning, enforces read\\-only safety, and gracefully manages errors. This directly addresses those common pain points we all face \\- LLM hallucinations, brittle SQL generation, and all that UI plumbing nobody wants to deal with. And yes, the whole thing runs in a Colab notebook with validation at each step.\n\n## Why This Approach Works\n\n**Graphs over tables**: Look, relational databases really struggle with multi\\-hop queries. You know, things like friends\\-of\\-friends or recommendation paths. Neo4j's native graph traversal makes these queries not just possible but actually fast and expressive.\n\n**GPT\\-4o for Cypher generation**: I've found that GPT\\-4o combines strong language understanding with surprisingly reliable structured output when you give it proper schema context and examples. This means you don't need hand\\-coded query templates anymore, and the system adapts when your schema evolves.\n\n**CrewAI for orchestration**: CrewAI gives you a lightweight agent framework that manages tool invocation and conversation flow. You don't have to build a custom orchestration layer from scratch, which, trust me, is more complicated than it sounds.\n\n**Chainlit for UI**: Here's the thing about Chainlit \\- it offers a chat interface with minimal boilerplate. You can focus on your backend logic instead of wrestling with frontend plumbing. And it supports streaming, tables, and charts right out of the box.\n\n**Read\\-only enforcement**: By restricting Cypher to MATCH/RETURN/CALL and using a read\\-only Neo4j role, you prevent accidental or malicious writes. This makes the system actually safe for production use, which is obviously critical.\n\n## Setup \\& Installation\n\nFirst, run this cell to install all dependencies with pinned versions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q neomodel==5.2.1 crewai==0.28.8 crewai-tools==0.1.6 openai==1.12.0 chainlit==1.0.200 python-dotenv==1.0.0 plotly==5.18.0 pandas==2.0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, you'll need to create a .env file with your credentials. This cell writes a template \\- just replace the placeholders with your real values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile .env\nNEO4J_URI=bolt+s://your-instance.databases.neo4j.io:7687\nNEO4J_USERNAME=neo4j\nNEO4J_PASSWORD=your-password\nOPENAI_API_KEY=sk-...\nOPENAI_MODEL=gpt-4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now load and validate your environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nrequired_keys = [\"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\", \"OPENAI_API_KEY\", \"OPENAI_MODEL\"]\nmissing = [k for k in required_keys if not os.getenv(k)]\nif missing:\n    raise EnvironmentError(f\"Missing required environment variables: {', '.join(missing)}\")\n\nprint(\"All required environment variables found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step\\-by\\-Step Implementation\n\n### Step 1: Connect to Neo4j and Validate\n\nLet's start by creating the directory structure and writing the Neo4j connection module. This module normalizes the URI, initializes the connection, and provides a test function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p tools utils config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile tools/query_knowledge_graph.py\nimport os\nfrom typing import Any, Dict, List, Tuple, Optional\nfrom neomodel import db, config as neo_config\nfrom dotenv import load_dotenv\n\nrequired_keys = [\"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\"]\nmissing = [k for k in required_keys if not os.getenv(k)]\nif missing:\n    raise EnvironmentError(\n        f\"Missing required environment variables: {', '.join(missing)}\\n\"\n        \"Please set them before running the application.\"\n    )\n\nprint(\"All required Neo4j environment variables found.\")\nload_dotenv()\n\n\ndef _normalize_neo4j_uri(uri: str) -> str:\n    return uri.replace(\"neo4j+s://\", \"bolt+s://\").replace(\"neo4j://\", \"bolt://\")\n\n\ndef init_neo4j_connection() -> None:\n    uri = os.getenv(\"NEO4J_URI\")\n    user = os.getenv(\"NEO4J_USERNAME\")\n    pwd = os.getenv(\"NEO4J_PASSWORD\")\n    if not uri or not user or not pwd:\n        raise RuntimeError(\"Missing Neo4j credentials.\")\n\n    bolt_uri = _normalize_neo4j_uri(uri)\n    neo_config.DATABASE_URL = bolt_uri\n    neo_config.MAX_POOL_SIZE = 20\n    db.set_connection(bolt_uri, user=user, password=pwd)\n    print(\"Neo4j connection initialized.\")\n\n\ndef test_connection() -> Tuple[List[Tuple[Any]], List[Dict[str, Any]]]:\n    return db.cypher_query(\"RETURN 'Connection successful' AS message\")\n\n\ndef safe_init() -> None:\n    try:\n        init_neo4j_connection()\n        res, _ = test_connection()\n        print(f\"Neo4j: {res[0][0]}\")\n    except Exception as e:\n        raise RuntimeError(f\"Neo4j connection failed: {e}\")\n\n\ndef run_cypher(cypher: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n    cypher_lower = cypher.strip().lower()\n    unsafe_keywords = [\"create\", \"merge\", \"delete\", \"set\", \"remove\", \"detach\"]\n    if any(kw in cypher_lower for kw in unsafe_keywords):\n        return {\"error\": \"Unsafe Cypher detected. Only read-only queries allowed.\", \"columns\": [], \"rows\": [], \"data\": []}\n\n    try:\n        results, meta = db.cypher_query(cypher, params or {})\n        columns = [m[\"name\"] for m in meta]\n        rows = [list(r) for r in results]\n        data = [dict(zip(columns, row)) for row in rows]\n        return {\"columns\": columns, \"rows\": rows, \"data\": data}\n    except Exception as e:\n        print(f\"Cypher execution error: {e}\")\n        return {\"error\": str(e), \"columns\": [], \"rows\": [], \"data\": []}\n\n\ndef query_knowledge_graph(nl_query: str, cypher: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n    result = run_cypher(cypher, params)\n    result[\"nl_query\"] = nl_query\n    result[\"cypher\"] = cypher\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the connection to make sure everything's working:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tools.query_knowledge_graph import safe_init, run_cypher\n\nsafe_init()\nprint(run_cypher(\"RETURN 1 AS one\"))\nprint(run_cypher(\"MATCH (n) RETURN count(n) AS nodes LIMIT 1\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should see something like: `{'columns': ['one'], 'rows': [[1]], 'data': [{'one': 1}]}` along with a node count.\n\n### Step 2: Define Agent and Task Configuration\n\nNow we'll write the agent and task YAML files. The agent uses GPT\\-4o and the knowledge graph tool to generate and execute Cypher queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile config/agents.yaml\ncypher_agent:\n  role: \"Knowledge Graph Query Specialist\"\n  goal: \"Generate accurate Cypher queries from natural language and return results.\"\n  backstory: |\n    You are an expert in Neo4j and Cypher. Given a schema and a question, you produce a valid Cypher query.\n    You always return the query in a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cypher code block, followed by any chart configuration in a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```json\nblock if visualization is requested.\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile config/tasks.yaml\ngenerate_and_execute_query:\n  description: |\n    Given the question: {question}\n    And the schema: {schema}\n    Generate a Cypher query to answer it. Return the query in a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cypher block.\n    If the user asks for a chart, also return a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```json\nblock with chart config (type, x, y, title).\n  expected_output: |\n    A\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cypher code block with the query, and optionally a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```json\nblock with chart config.\n  agent: cypher_agent\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Build the CrewAI Agent and Tool\n\nCreate a utility to load YAML configuration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/yaml_loader.py\nimport yaml\nfrom pathlib import Path\n\ndef load_yaml(file_path: str):\n    with open(Path(file_path), \"r\") as f:\n        return yaml.safe_load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the CrewAI tool wrapper for the knowledge graph query function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile tools/__init__.py\nfrom crewai_tools import tool\nfrom .query_knowledge_graph import query_knowledge_graph\n\n@tool(\"Query Knowledge Graph\")\ndef query_knowledge_graph_tool(nl_query: str, cypher: str) -> dict:\n    \"\"\"\n    Execute a Cypher query against the Neo4j knowledge graph.\n    Args:\n        nl_query (str): The natural language question.\n        cypher (str): The Cypher query to execute.\n    Returns:\n        dict: Query results with columns, rows, and data.\n    \"\"\"\n    return query_knowledge_graph(nl_query, cypher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Time to assemble the agent and task. This cell creates the agent, attaches the tool, and defines the task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile agent_setup.py\nimport os\nfrom crewai import Agent, Task, Crew\nfrom langchain_openai import ChatOpenAI\nfrom tools import query_knowledge_graph_tool\nfrom utils.yaml_loader import load_yaml\n\nagents_config = load_yaml(\"config/agents.yaml\")\ntasks_config = load_yaml(\"config/tasks.yaml\")\n\nllm = ChatOpenAI(model=os.getenv(\"OPENAI_MODEL\"), temperature=0)\n\ncypher_agent = Agent(\n    config=agents_config[\"cypher_agent\"],\n    tools=[query_knowledge_graph_tool],\n    llm=llm,\n    verbose=True\n)\n\ndef create_query_task(question: str, schema: str) -> Task:\n    return Task(\n        config=tasks_config[\"generate_and_execute_query\"],\n        agent=cypher_agent,\n        context={\"question\": question, \"schema\": schema}\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Parse Agent Output and Execute Tool\n\nWrite a parser to extract Cypher and chart JSON from the agent's response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils/parser.py\nimport re\nimport json\nfrom typing import Optional, Tuple\n\ndef extract_cypher(text: str) -> Optional[str]:\n    match = re.search(r\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cypher\\s+(.*?)\\s+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\", text, re.DOTALL | re.IGNORECASE)\n    return match.group(1).strip() if match else None\n\ndef extract_chart_config(text: str) -> Optional[dict]:\n    match = re.search(r\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "json\\s+(.*?)\\s+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\", text, re.DOTALL | re.IGNORECASE)\n    if match:\n        try:\n            return json.loads(match.group(1).strip())\n        except json.JSONDecodeError:\n            return None\n    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's test the agent and parser with a sample question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from agent_setup import cypher_agent, create_query_task\nfrom crewai import Crew\nfrom utils.parser import extract_cypher, extract_chart_config\n\nschema = \"\"\"\nNodes: Person(name, age), Movie(title, year)\nRelationships: (Person)-[:ACTED_IN]->(Movie), (Person)-[:DIRECTED]->(Movie)\n\"\"\"\n\nquestion = \"Who acted in movies released after 2010?\"\ntask = create_query_task(question, schema)\ncrew = Crew(agents=[cypher_agent], tasks=[task], verbose=True)\n\nresult = crew.kickoff()\nprint(\"Agent output:\", result)\n\ncypher = extract_cypher(str(result))\nchart_config = extract_chart_config(str(result))\nprint(\"Extracted Cypher:\", cypher)\nprint(\"Chart config:\", chart_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should get a Cypher query like `MATCH (p:Person)-[:ACTED_IN]->(m:Movie) WHERE m.year > 2010 RETURN p.name, m.title` and optionally a chart config JSON.\n\n### Step 5: Wire the Chainlit UI\n\nCreate the Chainlit app. This app maintains conversation history, sends questions to the agent, extracts and executes Cypher, and renders results as tables and charts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile chat.py\nimport os\nimport chainlit as cl\nfrom crewai import Crew\nfrom agent_setup import cypher_agent, create_query_task\nfrom tools.query_knowledge_graph import query_knowledge_graph, safe_init\nfrom utils.parser import extract_cypher, extract_chart_config\nimport plotly.graph_objects as go\nimport pandas as pd\n\nsafe_init()\n\nSCHEMA = \"\"\"\nNodes: Person(name, age), Movie(title, year)\nRelationships: (Person)-[:ACTED_IN]->(Movie), (Person)-[:DIRECTED]->(Movie)\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"history\", [])\n    await cl.Message(content=\"Ask me anything about the knowledge graph!\").send()\n\n@cl.on_message\nasync def main(message: cl.Message):\n    question = message.content\n    history = cl.user_session.get(\"history\")\n    history.append({\"role\": \"user\", \"content\": question})\n\n    task = create_query_task(question, SCHEMA)\n    crew = Crew(agents=[cypher_agent], tasks=[task], verbose=False)\n    \n    try:\n        result = crew.kickoff()\n        agent_output = str(result)\n        history.append({\"role\": \"assistant\", \"content\": agent_output})\n        cl.user_session.set(\"history\", history[-10:])\n\n        cypher = extract_cypher(agent_output)\n        chart_config = extract_chart_config(agent_output)\n\n        if not cypher:\n            await cl.Message(content=\"Could not extract a valid Cypher query.\").send()\n            return\n\n        query_result = query_knowledge_graph(question, cypher)\n\n        if \"error\" in query_result:\n            await cl.Message(content=f\"Query error: {query_result['error']}\").send()\n            return\n\n        df = pd.DataFrame(query_result[\"data\"])\n        table_md = df.to_markdown(index=False)\n        await cl.Message(content=f\"**Results:**\\n\\n{table_md}\").send()\n\n        if chart_config and not df.empty:\n            chart_type = chart_config.get(\"type\", \"bar\")\n            x_col = chart_config.get(\"x\")\n            y_col = chart_config.get(\"y\")\n            title = chart_config.get(\"title\", \"Chart\")\n\n            if x_col in df.columns and y_col in df.columns:\n                if chart_type == \"bar\":\n                    fig = go.Figure(data=[go.Bar(x=df[x_col], y=df[y_col])])\n                elif chart_type == \"line\":\n                    fig = go.Figure(data=[go.Scatter(x=df[x_col], y=df[y_col], mode='lines+markers')])\n                else:\n                    fig = go.Figure(data=[go.Bar(x=df[x_col], y=df[y_col])])\n                \n                fig.update_layout(title=title, xaxis_title=x_col, yaxis_title=y_col)\n                await cl.Message(content=\"\", elements=[cl.Plotly(name=\"chart\", figure=fig)]).send()\n\n    except Exception as e:\n        await cl.Message(content=f\"Error: {str(e)}\").send()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To run the Chainlit app in Colab, you can use a tunnel service like ngrok to expose it publicly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!chainlit run chat.py --host 0.0.0.0 --port 8000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're developing locally, just run `chainlit run chat.py` and open the provided URL.\n\n### Step 6: Validate End\\-to\\-End\n\nTest the complete system with a sample question. This cell simulates the agent workflow without the UI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from agent_setup import cypher_agent, create_query_task\nfrom crewai import Crew\nfrom tools.query_knowledge_graph import query_knowledge_graph\nfrom utils.parser import extract_cypher\n\nschema = \"\"\"\nNodes: Person(name, age), Movie(title, year)\nRelationships: (Person)-[:ACTED_IN]->(Movie)\n\"\"\"\n\nquestion = \"List all actors and their movies\"\ntask = create_query_task(question, schema)\ncrew = Crew(agents=[cypher_agent], tasks=[task], verbose=False)\n\nresult = crew.kickoff()\ncypher = extract_cypher(str(result))\nprint(\"Generated Cypher:\", cypher)\n\nif cypher:\n    query_result = query_knowledge_graph(question, cypher)\n    print(\"Query result:\", query_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should see a Cypher query and a result dictionary with columns, rows, and data.\n\n## Production Considerations\n\n**Read\\-only enforcement**: Use a Neo4j role with read\\-only permissions. The run\\_cypher function already rejects unsafe keywords, but you should validate this in your Neo4j user setup as well.\n\n**Error handling and retries**: You'll want to wrap OpenAI and Neo4j calls in retry logic with exponential backoff. Libraries like tenacity work great for handling transient 429 or network errors.\n\n**Token and cost control**: I recommend limiting conversation history to the last 10 messages. Prune or summarize older context. And definitely monitor token usage per request and set budget alerts in your OpenAI dashboard.\n\n**Logging and observability**: Add correlation IDs to each request. Log Cypher queries, parameters, execution time, and errors. Use structured logging (JSON) for easy parsing and alerting \\- this has saved me countless debugging hours.\n\n**Schema versioning**: Store schema definitions in version control. Update prompts when the schema changes. Always test queries against a staging graph before deploying to production. I learned this one the hard way.\n\n**Caching**: Cache normalized Cypher queries with a hash key and return saved results for repeated questions. Use an LRU cache with TTL. For deeper optimization, consider adding semantic caching with Redis Vector to reuse similar queries using embeddings. Actually, this can dramatically improve response times for common queries.\n\n**Testing**: Write unit tests for run\\_cypher, extract\\_cypher, and extract\\_chart\\_config. Create integration tests that validate end\\-to\\-end flows with seed data. Assert expected column names, row counts, and chart configs. Don't skip this \\- it'll save you from embarrassing production issues.\n\n## Conclusion and Next Steps\n\nSo you've built a knowledge graph chatbot that translates natural language into Cypher, executes queries safely, and visualizes results. The system uses GPT\\-4o for query generation, CrewAI for orchestration, and Chainlit for a conversational UI. You've implemented read\\-only enforcement, error handling, and incremental validation at each step.\n\nHere's what you can do next:\n\n* **Swap LLMs**: Replace GPT\\-4o with Claude or Llama by changing the llm parameter in agent\\_setup.py. Test prompt compatibility and adjust schema examples if needed. Each model has its quirks.\n* **Add RAG for schema context**: If your schema is large or dynamic, embed schema documentation and retrieve relevant subsets before query generation. Check out our guide to structured data extraction with LLMs for best practices on deterministic outputs.\n* **Integrate with external APIs**: Extend the agent with additional tools \\- REST API calls, database lookups, whatever you need to enrich query results or trigger actions based on graph insights.\n* **Deploy to production**: Containerize the app with Docker, set up environment\\-specific configs, and deploy to your cloud platform of choice (AWS, GCP, Azure). Use a reverse proxy like nginx and enable HTTPS. Don't forget this last part.\n* **Build stateful workflows**: For more complex agent behaviors, explore building a stateful AI agent with LangGraph to manage multi\\-turn conversations and conditional logic. This opens up a whole new world of possibilities."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o",
    "description": "Ship a Python knowledge graph chatbot using Neo4j, Chainlit, and GPT-4oâ€”auto-generate Cypher, visualize results, and answer complex data questions accurately.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}