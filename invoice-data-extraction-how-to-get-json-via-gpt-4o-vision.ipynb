{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** Invoice Data Extraction: How to Get JSON via GPT-4o Vision\n\n**Description:** Ship a production-ready, template-less invoice data extractor: jsonschema-validated JSON, retryable GPT-4o Vision, OCR fallback, and idempotent Postgres upserts with logs.\n\n**ðŸ“– Read the full article:** [Invoice Data Extraction: How to Get JSON via GPT-4o Vision](https://blog.thegenairevolution.com/article/invoice-data-extraction-how-to-get-json-via-gpt-4o-vision)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What You'll Build\n\nYou'll create a Colab\\-ready invoice extraction pipeline that takes PDF and image invoices and converts them into schema\\-validated JSON. The system persists everything to Postgres and logs every single API call for observability. It uses GPT\\-4o Vision for extraction, validates output against a strict JSON Schema, repairs failures with targeted retry loops, and falls back to OCR when vision fails. Plus, it ensures idempotent writes. You'll run it on sample invoices and verify correctness from start to finish.\n\nPrerequisites: You'll need an OpenAI API key, a Postgres DSN (grab a free\\-tier managed instance from Neon or ElephantSQL if you don't have one), and about 30 minutes. This tutorial focuses on the extraction and validation pipeline. Deployment and UI are out of scope.\n\n## How It Works (High\\-Level Overview)\n\n1. **File ingestion** â€“ Load PDF or image invoices and convert them to images\n2. **Image preprocessing** â€“ Optionally resize and enhance for OCR\n3. **Vision extraction** â€“ Call GPT\\-4o Vision to extract structured JSON\n4. **Schema validation** â€“ Validate against JSON Schema and collect all errors\n5. **Repair loop** â€“ If validation fails, send errors back to the model with retry logic\n6. **Numeric consistency check** â€“ Verify line item totals match subtotal and tax\n7. **OCR fallback** â€“ If vision fails, preprocess image, run Tesseract, and extract from text\n8. **Postgres upsert** â€“ Persist document and line items idempotently by hash\n9. **Logging** â€“ Record latency, token usage, and errors for every run\n10. **Verification** â€“ Query results and confirm idempotency on re\\-run\n\n## Setup: Install Dependencies\n\nRun this cell first to install Python packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --quiet openai pytesseract Pillow opencv-python pdf2image jsonschema psycopg2-binary tenacity python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install system dependencies for Tesseract and Poppler (PDF rendering):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install -y tesseract-ocr poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Credentials\n\nPrompt for API key and database connection string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom getpass import getpass\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n\nif \"POSTGRES_DSN\" not in os.environ:\n    os.environ[\"POSTGRES_DSN\"] = getpass(\"Enter your Postgres DSN (postgresql://user:pass@host:port/db): \")\n\n# Verify credentials are set\nassert os.environ.get(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY is required\"\nassert os.environ.get(\"POSTGRES_DSN\"), \"POSTGRES_DSN is required\"\n\nprint(\"âœ“ Credentials configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternative for Colab: Use `from google.colab import userdata` and store secrets in Colab's secret manager.\n\n## Initialize Database Schema\n\nCreate tables for documents, line items, and processing logs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import psycopg2\n\nconn = psycopg2.connect(os.environ[\"POSTGRES_DSN\"])\ncur = conn.cursor()\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS documents (\n    id SERIAL PRIMARY KEY,\n    document_hash TEXT UNIQUE NOT NULL,\n    filename TEXT,\n    vendor TEXT,\n    invoice_number TEXT,\n    invoice_date DATE,\n    currency TEXT,\n    subtotal NUMERIC(12,2),\n    tax NUMERIC(12,2),\n    total NUMERIC(12,2),\n    data JSONB,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n)\n\"\"\")\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS line_items (\n    id SERIAL PRIMARY KEY,\n    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,\n    line_number INTEGER,\n    description TEXT,\n    quantity NUMERIC(12,3),\n    unit_price NUMERIC(12,2),\n    line_total NUMERIC(12,2)\n)\n\"\"\")\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS processing_logs (\n    id SERIAL PRIMARY KEY,\n    document_hash TEXT,\n    request_id TEXT,\n    status TEXT,\n    latency_ms INTEGER,\n    prompt_tokens INTEGER,\n    completion_tokens INTEGER,\n    total_tokens INTEGER,\n    error_message TEXT,\n    created_at TIMESTAMP DEFAULT NOW()\n)\n\"\"\")\n\nconn.commit()\ncur.close()\nconn.close()\n\nprint(\"âœ“ Database schema initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Provision Sample Invoices\n\nDownload sample invoices to `/content/invoices`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nimport urllib.request\n\nos.makedirs(\"/content/invoices\", exist_ok=True)\n\nsamples = [\n    (\"https://templates.invoicehome.com/invoice-template-us-neat-750px.png\", \"sample1.png\"),\n    (\"https://www.freshbooks.com/wp-content/uploads/2021/10/invoice-sample.jpg\", \"sample2.jpg\"),\n]\n\nfor url, filename in samples:\n    path = f\"/content/invoices/{filename}\"\n    if not os.path.exists(path):\n        urllib.request.urlretrieve(url, path)\n        print(f\"âœ“ Downloaded {filename}\")\n    else:\n        print(f\"âœ“ {filename} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** Replace with your own invoice files if needed.\n\n## Define the Invoice JSON Schema\n\nStrict schema with required fields and types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "invoice_schema = {\n    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n    \"title\": \"Invoice\",\n    \"type\": \"object\",\n    \"required\": [\"vendor\", \"invoice_number\", \"invoice_date\", \"currency\", \"subtotal\", \"tax\", \"total\", \"line_items\"],\n    \"properties\": {\n        \"vendor\": {\"type\": \"string\", \"minLength\": 1},\n        \"invoice_number\": {\"type\": \"string\", \"pattern\": \"^[A-Za-z0-9._\\-/]+$\"},\n        \"invoice_date\": {\"type\": \"string\", \"pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\"},\n        \"due_date\": {\"type\": \"string\", \"pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\"},\n        \"currency\": {\"type\": \"string\", \"pattern\": \"^[A-Z]{3}$\"},\n        \"subtotal\": {\"type\": \"number\"},\n        \"tax\": {\"type\": \"number\"},\n        \"total\": {\"type\": \"number\"},\n        \"vendor_address\": {\"type\": \"string\"},\n        \"customer\": {\"type\": \"string\"},\n        \"customer_address\": {\"type\": \"string\"},\n        \"notes\": {\"type\": \"string\"},\n        \"line_items\": {\n            \"type\": \"array\",\n            \"minItems\": 1,\n            \"items\": {\n                \"type\": \"object\",\n                \"required\": [\"description\", \"quantity\", \"unit_price\", \"line_total\"],\n                \"properties\": {\n                    \"description\": {\"type\": \"string\", \"minLength\": 1},\n                    \"quantity\": {\"type\": \"number\"},\n                    \"unit_price\": {\"type\": \"number\"},\n                    \"line_total\": {\"type\": \"number\"},\n                    \"sku\": {\"type\": \"string\"}\n                },\n                \"additionalProperties\": False\n            }\n        }\n    },\n    \"additionalProperties\": False\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Setting `additionalProperties: false` prevents hallucinated fields. Patterns ensure dates and currency codes are valid.\n\n## Compute Document Hash for Idempotency\n\nHash each file to detect duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import hashlib\n\ndef compute_document_hash(file_path: str) -> str:\n    \"\"\"Compute SHA-256 hash of a file for idempotency.\"\"\"\n    h = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(8192), b\"\"):\n            h.update(chunk)\n    return h.hexdigest()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Hashing prevents reprocessing the same file and enables `ON CONFLICT` upserts.\n\n## Convert Files to Images\n\nHandle PDFs and common image formats:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\nfrom pdf2image import convert_from_path\n\ndef file_to_images(file_path: str):\n    \"\"\"Convert a file to a list of PIL images.\"\"\"\n    ext = os.path.splitext(file_path)[1].lower()\n    if ext in [\".png\", \".jpg\", \".jpeg\", \".webp\", \".tiff\", \".bmp\"]:\n        return [Image.open(file_path).convert(\"RGB\")]\n    elif ext == \".pdf\":\n        pages = convert_from_path(file_path, dpi=300)\n        return [p.convert(\"RGB\") for p in pages]\n    else:\n        raise ValueError(f\"Unsupported file type: {ext}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** DPI 300 balances quality and token cost. For multi\\-page PDFs, we process only the first page in this tutorial.\n\n## Resize Images to Control Token Usage\n\nLimit image size to reduce API cost:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize_image_for_vision(img: Image.Image, max_long_edge: int = 1600) -> Image.Image:\n    \"\"\"Resize image if longest edge exceeds max_long_edge.\"\"\"\n    w, h = img.size\n    if max(w, h) <= max_long_edge:\n        return img\n    scale = max_long_edge / max(w, h)\n    new_w, new_h = int(w * scale), int(h * scale)\n    return img.resize((new_w, new_h), Image.LANCZOS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trade\\-off:** Smaller images reduce cost but may hurt OCR accuracy on small fonts. Adjust `max_long_edge` as needed.\n\n## Preprocess Images for OCR\n\nEnhance readability with grayscale, thresholding, and deskew:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\nimport numpy as np\n\ndef preprocess_for_ocr(pil_img: Image.Image) -> Image.Image:\n    \"\"\"Preprocess image for OCR by applying grayscale, thresholding, and deskew.\"\"\"\n    img = np.array(pil_img)\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                               cv2.THRESH_BINARY, 35, 11)\n    \n    # Deskew via moments (guard against empty image)\n    coords = np.column_stack(np.where(th > 0))\n    if len(coords) == 0:\n        return Image.fromarray(th)\n    \n    angle = cv2.minAreaRect(coords)[-1]\n    if angle < -45:\n        angle = -(90 + angle)\n    else:\n        angle = -angle\n    \n    (h, w) = th.shape[:2]\n    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n    rotated = cv2.warpAffine(th, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n    return Image.fromarray(rotated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Adaptive thresholding handles uneven lighting. Deskew corrects rotation. The guard prevents crashes on blank images.\n\n## Run Tesseract OCR\n\nExtract text as a fallback:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytesseract\n\ndef ocr_extract_text(pil_img: Image.Image) -> str:\n    \"\"\"Extract text from an image using Tesseract OCR.\"\"\"\n    return pytesseract.image_to_string(pil_img, lang=\"eng\", config=\"--psm 6 --oem 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** `--psm 6` assumes uniform text blocks. `--oem 1` uses LSTM for better accuracy.\n\n## Convert Image to Data URL\n\nEncode image for Vision API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\nfrom io import BytesIO\n\ndef pil_to_data_url(img: Image.Image) -> str:\n    \"\"\"Convert a PIL image to a data URL.\"\"\"\n    buf = BytesIO()\n    img.save(buf, format=\"PNG\")\n    b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n    return f\"data:image/png;base64,{b64}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define System Prompt and Few\\-Shot Examples\n\nGuide the model with strict instructions and a concrete example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = (\n    \"You are a careful invoicing parser. Extract fields strictly as JSON. \"\n    \"Do not include any text outside the JSON. If a value is missing, infer cautiously \"\n    \"from context; otherwise omit the field. Use ISO 8601 dates (YYYY-MM-DD) and ISO 4217 currency.\"\n)\n\ndef schema_summary(schema: dict) -> str:\n    \"\"\"Summarize required fields and types for the prompt.\"\"\"\n    req = schema.get(\"required\", [])\n    props = schema.get(\"properties\", {})\n    lines = [\"Required fields and types:\"]\n    for k in req:\n        t = props.get(k, {}).get(\"type\", \"any\")\n        lines.append(f\"- {k}: {t}\")\n    lines.append(\"Line item fields: description (string), quantity (number), unit_price (number), line_total (number).\")\n    return \"\\n\".join(lines)\n\nFEW_SHOT_USER = (\n    \"Example: Extract JSON from this text-only invoice:\\n\"\n    \"ACME Corp\\nInvoice INV-123\\nDate 2024-06-01\\n\"\n    \"1x Widget A @ 10.00\\n2x Widget B @ 5.00\\nSubtotal 20.00\\nTax 2.00\\nTotal 22.00\\n\"\n)\n\nFEW_SHOT_ASSISTANT = \"\"\"{\n  \"vendor\": \"ACME Corp\",\n  \"invoice_number\": \"INV-123\",\n  \"invoice_date\": \"2024-06-01\",\n  \"currency\": \"USD\",\n  \"subtotal\": 20.0,\n  \"tax\": 2.0,\n  \"total\": 22.0,\n  \"line_items\": [\n    {\"description\": \"Widget A\", \"quantity\": 1, \"unit_price\": 10.0, \"line_total\": 10.0},\n    {\"description\": \"Widget B\", \"quantity\": 2, \"unit_price\": 5.0, \"line_total\": 10.0}\n  ]\n}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Few\\-shot examples anchor the model's output format and reduce hallucinations.\n\n## Call GPT\\-4o Vision with Retry Logic\n\nExtract invoice data from an image with automatic retries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\nimport time\nfrom openai import OpenAI\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\nclient = OpenAI()\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef call_gpt4o_vision(img: Image.Image, schema: dict):\n    \"\"\"Call GPT-4o Vision API to extract invoice data as JSON.\"\"\"\n    data_url = pil_to_data_url(img)\n    start = time.time()\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": \"Extract an invoice as JSON. Follow this contract:\\n\" + schema_summary(schema)},\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n                ]\n            }\n        ],\n        temperature=0.2\n    )\n    latency_ms = int((time.time() - start) * 1000)\n    text = resp.choices[0].message.content\n    usage = resp.usage\n    request_id = resp.id\n    return json.loads(text), latency_ms, usage, request_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** `response_format=json_object` forces JSON output. Retry logic handles transient API errors.\n\n## Validate Against JSON Schema\n\nCollect all validation errors for targeted repair:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jsonschema import Draft202012Validator, ValidationError\n\ndef validate_against_schema(data: dict, schema: dict):\n    \"\"\"Validate data against the JSON schema and return all errors.\"\"\"\n    validator = Draft202012Validator(schema)\n    errors = []\n    for e in validator.iter_errors(data):\n        path = \"/\".join(map(str, e.path)) or \"$\"\n        errors.append(f\"path={path}: {e.message}\")\n    return len(errors) == 0, errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Collecting all errors at once gives the model complete context for repair.\n\n## Repair JSON with Targeted Feedback\n\nSend validation errors back to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef repair_with_gpt(img: Image.Image, schema: dict, prev: dict, errors: list):\n    \"\"\"Repair JSON data using GPT-4o Vision based on validation errors.\"\"\"\n    data_url = pil_to_data_url(img)\n    prompt = \"The previous JSON failed validation. Fix strictly per errors:\\n\" + \"\\n\".join(f\"- {err}\" for err in errors)\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"text\", \"text\": \"Original image for reference:\"},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n            ]},\n            {\"role\": \"user\", \"content\": f\"Previous JSON:\\n{json.dumps(prev, ensure_ascii=False)}\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ],\n        temperature=0.1\n    )\n    fixed = json.loads(resp.choices[0].message.content)\n    return fixed, resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Lower temperature (0\\.1\\) reduces creativity during repair. Showing the original image maintains context.\n\n## Check Numeric Consistency\n\nVerify line item totals match subtotal and tax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def numeric_consistency_ok(data: dict, tol: float = 0.05):\n    \"\"\"Check if numeric fields in the data are consistent within a tolerance.\"\"\"\n    try:\n        subtotal = float(data.get(\"subtotal\", 0))\n        tax = float(data.get(\"tax\", 0))\n        total = float(data.get(\"total\", 0))\n        li_sum = sum(float(it.get(\"line_total\", 0)) for it in data.get(\"line_items\", []))\n        return (abs(li_sum - subtotal) <= tol and\n                abs(subtotal + tax - total) <= tol)\n    except Exception:\n        return False\n\ndef build_numeric_errors(data: dict):\n    \"\"\"Build error messages for numeric inconsistencies.\"\"\"\n    subtotal = data.get(\"subtotal\", None)\n    tax = data.get(\"tax\", None)\n    total = data.get(\"total\", None)\n    li_sum = sum(float(it.get(\"line_total\", 0)) for it in data.get(\"line_items\", []))\n    msgs = []\n    msgs.append(f\"Sum(line_items.line_total)={li_sum}, subtotal={subtotal}, tax={tax}, total={total}.\")\n    msgs.append(\"Enforce: sum(line_items) â‰ˆ subtotal; subtotal + tax â‰ˆ total; update fields minimally to satisfy.\")\n    return msgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Tolerance accounts for rounding. Explicit error messages guide the model to fix arithmetic.\n\n## Fallback to OCR and Text\\-Only Extraction\n\nIf vision fails, preprocess and extract from text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef call_gpt_text_only(ocr_text: str, schema: dict, extra_instructions: str = \"\"):\n    \"\"\"Call GPT-4o using OCR text to extract invoice data as JSON.\"\"\"\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\"role\": \"user\", \"content\": \"Extract invoice JSON strictly per schema summary:\\n\" + schema_summary(schema)},\n            {\"role\": \"user\", \"content\": f\"Invoice text:\\n{ocr_text}\"},\n            {\"role\": \"user\", \"content\": extra_instructions} if extra_instructions else {\"role\": \"user\", \"content\": \"\"}\n        ],\n        temperature=0.2\n    )\n    data = json.loads(resp.choices[0].message.content)\n    return data, resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Passing numeric errors as a separate message keeps the invoice text clean and improves repair signal.\n\n## Persist Results to Postgres\n\nUpsert document and replace line items idempotently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upsert_document(conn, doc_hash: str, filename: str, data: dict):\n    \"\"\"Upsert document data into Postgres and replace line items.\"\"\"\n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            INSERT INTO documents (document_hash, filename, vendor, invoice_number, invoice_date, currency,\n                                   subtotal, tax, total, data, created_at, updated_at)\n            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())\n            ON CONFLICT (document_hash) DO UPDATE SET\n                filename = EXCLUDED.filename,\n                vendor = EXCLUDED.vendor,\n                invoice_number = EXCLUDED.invoice_number,\n                invoice_date = EXCLUDED.invoice_date,\n                currency = EXCLUDED.currency,\n                subtotal = EXCLUDED.subtotal,\n                tax = EXCLUDED.tax,\n                total = EXCLUDED.total,\n                data = EXCLUDED.data,\n                updated_at = NOW()\n            RETURNING id\n        \"\"\", (\n            doc_hash, filename,\n            data.get(\"vendor\"),\n            data.get(\"invoice_number\"),\n            data.get(\"invoice_date\"),\n            data.get(\"currency\"),\n            data.get(\"subtotal\"),\n            data.get(\"tax\"),\n            data.get(\"total\"),\n            json.dumps(data),\n        ))\n        doc_id = cur.fetchone()[0]\n        \n        # Replace line items\n        cur.execute(\"DELETE FROM line_items WHERE document_id = %s\", (doc_id,))\n        for idx, it in enumerate(data.get(\"line_items\", []), start=1):\n            cur.execute(\"\"\"\n                INSERT INTO line_items (document_id, line_number, description, quantity, unit_price, line_total)\n                VALUES (%s, %s, %s, %s, %s, %s)\n            \"\"\", (\n                doc_id, idx,\n                it.get(\"description\"),\n                it.get(\"quantity\"),\n                it.get(\"unit_price\"),\n                it.get(\"line_total\")\n            ))\n    conn.commit()\n    return doc_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** `ON CONFLICT` ensures re\\-runs update existing records. Deleting and reinserting line items keeps them in sync.\n\n## Log Processing Metadata\n\nTrack latency, token usage, and errors for observability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_processing(conn, doc_hash: str, request_id: str, status: str, latency_ms: int,\n                   usage=None, error_message: str = None):\n    \"\"\"Log processing details into the database for observability.\"\"\"\n    # Sanitize error message to avoid logging large payloads\n    if error_message and len(error_message) > 500:\n        error_message = error_message[:500] + \"... (truncated)\"\n    \n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            INSERT INTO processing_logs (document_hash, request_id, status, latency_ms,\n                                         prompt_tokens, completion_tokens, total_tokens, error_message, created_at)\n            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW())\n        \"\"\", (\n            doc_hash,\n            request_id,\n            status,\n            latency_ms,\n            getattr(usage, \"prompt_tokens\", None) if usage else None,\n            getattr(usage, \"completion_tokens\", None) if usage else None,\n            getattr(usage, \"total_tokens\", None) if usage else None,\n            error_message\n        ))\n    conn.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Truncating error messages prevents PII leakage and keeps logs manageable.\n\n## Orchestrate the End\\-to\\-End Pipeline\n\nProcess a single invoice file through all steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n\ndef process_invoice_file(file_path: str):\n    \"\"\"Process an invoice file through the full pipeline.\"\"\"\n    doc_hash = compute_document_hash(file_path)\n    images = file_to_images(file_path)\n    first_img = resize_image_for_vision(images[0])\n\n    data = None\n    usage = None\n    request_id = None\n    status = \"ok\"\n    error_message = None\n    start_time = time.time()\n\n    try:\n        # Attempt Vision extraction\n        data, _, usage, request_id = call_gpt4o_vision(first_img, invoice_schema)\n        ok, errs = validate_against_schema(data, invoice_schema)\n        \n        # Repair if validation fails\n        if not ok:\n            data, repair_resp = repair_with_gpt(first_img, invoice_schema, data, errs)\n            usage = repair_resp.usage\n            request_id = repair_resp.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n\n        # Numeric consistency repair\n        if ok and not numeric_consistency_ok(data):\n            numeric_errs = build_numeric_errors(data)\n            data, repair_resp2 = repair_with_gpt(first_img, invoice_schema, data, numeric_errs)\n            usage = repair_resp2.usage\n            request_id = repair_resp2.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n\n        # OCR fallback\n        if not ok:\n            pre = preprocess_for_ocr(first_img)\n            ocr_text = ocr_extract_text(pre)\n            data, text_resp = call_gpt_text_only(ocr_text, invoice_schema)\n            usage = text_resp.usage\n            request_id = text_resp.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n            \n            # Numeric repair for OCR path\n            if ok and not numeric_consistency_ok(data):\n                numeric_errs = build_numeric_errors(data)\n                data, repair_resp3 = call_gpt_text_only(ocr_text, invoice_schema, \"\\n\".join(numeric_errs))\n                usage = repair_resp3.usage\n                request_id = repair_resp3.id\n                ok, errs = validate_against_schema(data, invoice_schema)\n\n        if not ok:\n            status = \"failed\"\n            error_message = \"Validation failed after OCR fallback: \" + \"; \".join(errs)\n\n        # Persist if successful\n        latency_ms = int((time.time() - start_time) * 1000)\n        if status == \"ok\":\n            with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n                upsert_document(conn, doc_hash, os.path.basename(file_path), data)\n                log_processing(conn, doc_hash, request_id, status, latency_ms, usage, None)\n        else:\n            with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n                log_processing(conn, doc_hash, request_id, status, latency_ms, usage, error_message)\n\n        return {\"file\": file_path, \"hash\": doc_hash, \"status\": status, \"errors\": None if status == \"ok\" else error_message}\n\n    except Exception as e:\n        status = \"error\"\n        error_message = str(e)\n        latency_ms = int((time.time() - start_time) * 1000)\n        with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n            log_processing(conn, doc_hash, request_id, status, latency_ms, usage, error_message)\n        return {\"file\": file_path, \"hash\": doc_hash, \"status\": status, \"errors\": error_message}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Tracking `start_time` at the top captures end\\-to\\-end latency. Each path (vision, repair, OCR) updates usage and `request_id` for accurate logging.\n\n## Run the Pipeline on Sample Files\n\nProcess all invoices in the input directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dir = \"/content/invoices\"\nfiles = sorted([p for p in glob.glob(os.path.join(input_dir, \"*\")) if os.path.isfile(p)])\n\nresults = []\nfor f in files:\n    res = process_invoice_file(f)\n    print(res)\n    results.append(res)\n\nsummary = {\n    \"processed\": len(results),\n    \"ok\": sum(1 for r in results if r[\"status\"] == \"ok\"),\n    \"failed\": sum(1 for r in results if r[\"status\"] == \"failed\"),\n    \"error\": sum(1 for r in results if r[\"status\"] == \"error\"),\n}\nprint(\"Summary:\", summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Idempotency\n\nRe\\-run processing and confirm no duplicates are created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count documents before re-run\nwith psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT COUNT(*) FROM documents\")\n        count_before = cur.fetchone()[0]\n\n# Re-run processing\nfor f in files:\n    res = process_invoice_file(f)\n    print(\"Re-run:\", res)\n\n# Count documents after re-run\nwith psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT COUNT(*) FROM documents\")\n        count_after = cur.fetchone()[0]\n\nprint(f\"Documents before: {count_before}, after: {count_after}\")\nassert count_before == count_after, \"Idempotency check failed: duplicate documents created\"\nprint(\"âœ“ Idempotency verified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Asserting equal counts proves `ON CONFLICT` works. Only `updated_at` should change.\n\n## Query and Inspect Results\n\nView extracted documents and line items:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            SELECT id, filename, vendor, invoice_number, invoice_date, currency, subtotal, tax, total\n            FROM documents ORDER BY id DESC LIMIT 5\n        \"\"\")\n        print(\"Documents:\")\n        for row in cur.fetchall():\n            print(row)\n\n        cur.execute(\"\"\"\n            SELECT d.invoice_number, li.line_number, li.description, li.quantity, li.unit_price, li.line_total\n            FROM line_items li\n            JOIN documents d ON li.document_id = d.id\n            ORDER BY d.id DESC, li.line_number ASC\n            LIMIT"
      ]
    }
  ],
  "metadata": {
    "title": "Invoice Data Extraction: How to Get JSON via GPT-4o Vision",
    "description": "Ship a production-ready, template-less invoice data extractor: jsonschema-validated JSON, retryable GPT-4o Vision, OCR fallback, and idempotent Postgres upserts with logs.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}