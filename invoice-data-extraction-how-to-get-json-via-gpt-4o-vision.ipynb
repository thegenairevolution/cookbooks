{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** Invoice Data Extraction: How to Get JSON via GPT-4o Vision\n\n**Description:** Ship a production-ready, template-less invoice data extractor: jsonschema-validated JSON, retryable GPT-4o Vision, OCR fallback, and idempotent Postgres upserts with logs.\n\n**ðŸ“– Read the full article:** [Invoice Data Extraction: How to Get JSON via GPT-4o Vision](https://blog.thegenairevolution.com/article/invoice-data-extraction-how-to-get-json-via-gpt-4o-vision-3)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alright, this is going to be a long one. I'm going to show you how to build something that actually works. An invoice extraction pipeline that takes those messy PDFs and images and turns them into clean, validated JSON. The whole thing runs in Colab, persists to Postgres, and logs everything so you can see what's happening under the hood.\n\nI've been working on this kind of system for a while now, and let me tell you, it's way trickier than it looks at first. You've got GPT\\-4o Vision doing the heavy lifting, sure, but when that fails (and trust me, it will), we fall back to good old OCR. Plus, we validate everything against a strict schema and fix errors automatically. Here's the kicker: the whole thing is idempotent, so you can run it multiple times without creating duplicates. That's something I learned the hard way in a previous project where duplicate processing was eating up our database.\n\n![Uploaded image](/public-objects/user_insert_44830763_1762963916007.png \"Uploaded image\")\n\nPrerequisites: Grab yourself an OpenAI API key and a Postgres DSN. You can get a free\\-tier managed instance from Neon or ElephantSQL if you don't have one lying around. Should take about 30 minutes to run through everything. Just so we're clear, this tutorial is about the extraction and validation pipeline. Deployment and UI? That's a whole other story that I'll probably tackle in another article.\n\n## How It Works (High\\-Level Overview)\n\n1. **File ingestion** â€“ Load up those PDF or image invoices and convert them to images\n\n2. **Image preprocessing** â€“ Maybe resize and enhance them for OCR if needed\n\n3. **Vision extraction** â€“ Hit GPT\\-4o Vision to pull out structured JSON\n\n4. **Schema validation** â€“ Check against JSON Schema and collect every single error\n\n5. **Repair loop** â€“ When validation fails, send those errors back to the model with retry logic\n\n6. **Numeric consistency check** â€“ Make sure line item totals actually match the subtotal and tax\n\n7. **OCR fallback** â€“ If vision craps out, preprocess the image, run Tesseract, extract from text\n\n8. **Postgres upsert** â€“ Save document and line items idempotently using hash\n\n9. **Logging** â€“ Track latency, token usage, errors for every single run\n\n10. **Verification** â€“ Query your results and make sure idempotency works on re\\-run\n\n## Setup: Install Dependencies\n\nFirst things first, let's get the Python packages installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --quiet openai pytesseract Pillow opencv-python pdf2image jsonschema psycopg2-binary tenacity python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the system dependencies for Tesseract and Poppler. You need these for PDF rendering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install -y tesseract-ocr poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Credentials\n\nTime to set up your API key and database connection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom getpass import getpass\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n\nif \"POSTGRES_DSN\" not in os.environ:\n    os.environ[\"POSTGRES_DSN\"] = getpass(\"Enter your Postgres DSN (postgresql://user:pass@host:port/db): \")\n\n# Verify credentials are set\nassert os.environ.get(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY is required\"\nassert os.environ.get(\"POSTGRES_DSN\"), \"POSTGRES_DSN is required\"\n\nprint(\"âœ“ Credentials configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actually, if you're using Colab, there's another way that I've found pretty handy. You can use `from google.colab import userdata` and stick your secrets in Colab's secret manager. Works pretty well actually, and you don't have to worry about accidentally committing your keys to GitHub.\n\n## Initialize Database Schema\n\nLet's create the tables for documents, line items, and processing logs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import psycopg2\n\nconn = psycopg2.connect(os.environ[\"POSTGRES_DSN\"])\ncur = conn.cursor()\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS documents (\n    id SERIAL PRIMARY KEY,\n    document_hash TEXT UNIQUE NOT NULL,\n    filename TEXT,\n    vendor TEXT,\n    invoice_number TEXT,\n    invoice_date DATE,\n    currency TEXT,\n    subtotal NUMERIC(12,2),\n    tax NUMERIC(12,2),\n    total NUMERIC(12,2),\n    data JSONB,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n)\n\"\"\")\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS line_items (\n    id SERIAL PRIMARY KEY,\n    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,\n    line_number INTEGER,\n    description TEXT,\n    quantity NUMERIC(12,3),\n    unit_price NUMERIC(12,2),\n    line_total NUMERIC(12,2)\n)\n\"\"\")\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS processing_logs (\n    id SERIAL PRIMARY KEY,\n    document_hash TEXT,\n    request_id TEXT,\n    status TEXT,\n    latency_ms INTEGER,\n    prompt_tokens INTEGER,\n    completion_tokens INTEGER,\n    total_tokens INTEGER,\n    error_message TEXT,\n    created_at TIMESTAMP DEFAULT NOW()\n)\n\"\"\")\n\nconn.commit()\ncur.close()\nconn.close()\n\nprint(\"âœ“ Database schema initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Provision Sample Invoices\n\nDownload some sample invoices to `/content/invoices`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nimport urllib.request\n\nos.makedirs(\"/content/invoices\", exist_ok=True)\n\nsamples = [\n    (\"https://templates.invoicehome.com/invoice-template-us-neat-750px.png\", \"sample1.png\"),\n    (\"https://www.freshbooks.com/wp-content/uploads/2021/10/invoice-sample.jpg\", \"sample2.jpg\"),\n]\n\nfor url, filename in samples:\n    path = f\"/content/invoices/{filename}\"\n    if not os.path.exists(path):\n        urllib.request.urlretrieve(url, path)\n        print(f\"âœ“ Downloaded {filename}\")\n    else:\n        print(f\"âœ“ {filename} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** Feel free to swap these out with your own invoice files. Actually, the more variety you throw at this thing, the better. I once tested with just one type of invoice and thought everything was perfect. Then production hit and, well, let's just say I learned about edge cases real quick.\n\n## Define the Invoice JSON Schema\n\nHere's where we get strict. Required fields, specific types, the works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "invoice_schema = {\n    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n    \"title\": \"Invoice\",\n    \"type\": \"object\",\n    \"required\": [\"vendor\", \"invoice_number\", \"invoice_date\", \"currency\", \"subtotal\", \"tax\", \"total\", \"line_items\"],\n    \"properties\": {\n        \"vendor\": {\"type\": \"string\", \"minLength\": 1},\n        \"invoice_number\": {\"type\": \"string\", \"pattern\": \"^[A-Za-z0-9._\\-/]+$\"},\n        \"invoice_date\": {\"type\": \"string\", \"pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\"},\n        \"due_date\": {\"type\": \"string\", \"pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\"},\n        \"currency\": {\"type\": \"string\", \"pattern\": \"^[A-Z]{3}$\"},\n        \"subtotal\": {\"type\": \"number\"},\n        \"tax\": {\"type\": \"number\"},\n        \"total\": {\"type\": \"number\"},\n        \"vendor_address\": {\"type\": \"string\"},\n        \"customer\": {\"type\": \"string\"},\n        \"customer_address\": {\"type\": \"string\"},\n        \"notes\": {\"type\": \"string\"},\n        \"line_items\": {\n            \"type\": \"array\",\n            \"minItems\": 1,\n            \"items\": {\n                \"type\": \"object\",\n                \"required\": [\"description\", \"quantity\", \"unit_price\", \"line_total\"],\n                \"properties\": {\n                    \"description\": {\"type\": \"string\", \"minLength\": 1},\n                    \"quantity\": {\"type\": \"number\"},\n                    \"unit_price\": {\"type\": \"number\"},\n                    \"line_total\": {\"type\": \"number\"},\n                    \"sku\": {\"type\": \"string\"}\n                },\n                \"additionalProperties\": False\n            }\n        }\n    },\n    \"additionalProperties\": False\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Setting `additionalProperties: false` is crucial. It stops the model from making stuff up, which believe me, it loves to do. And those patterns? They make sure dates and currency codes are actually valid. I spent way too much time debugging weird date formats before I added these.\n\n## Compute Document Hash for Idempotency\n\nWe hash each file to catch duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import hashlib\n\ndef compute_document_hash(file_path: str) -> str:\n    \"\"\"Compute SHA-256 hash of a file for idempotency.\"\"\"\n    h = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(8192), b\"\"):\n            h.update(chunk)\n    return h.hexdigest()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** This is how we avoid reprocessing the same file over and over. The hash enables those `ON CONFLICT` upserts later. Simple but effective.\n\n## Convert Files to Images\n\nHandle both PDFs and regular image formats:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\nfrom pdf2image import convert_from_path\n\ndef file_to_images(file_path: str):\n    \"\"\"Convert a file to a list of PIL images.\"\"\"\n    ext = os.path.splitext(file_path)[1].lower()\n    if ext in [\".png\", \".jpg\", \".jpeg\", \".webp\", \".tiff\", \".bmp\"]:\n        return [Image.open(file_path).convert(\"RGB\")]\n    elif ext == \".pdf\":\n        pages = convert_from_path(file_path, dpi=300)\n        return [p.convert(\"RGB\") for p in pages]\n    else:\n        raise ValueError(f\"Unsupported file type: {ext}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** DPI 300 is the sweet spot I've found. Good quality without blowing up your token costs. For multi\\-page PDFs, we're just doing the first page in this tutorial. You could extend it though. Actually, in one of my experiments, I tried processing all pages and the costs got... interesting.\n\n## Resize Images to Control Token Usage\n\nKeep those API costs down by limiting image size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize_image_for_vision(img: Image.Image, max_long_edge: int = 1600) -> Image.Image:\n    \"\"\"Resize image if longest edge exceeds max_long_edge.\"\"\"\n    w, h = img.size\n    if max(w, h) <= max_long_edge:\n        return img\n    scale = max_long_edge / max(w, h)\n    new_w, new_h = int(w * scale), int(h * scale)\n    return img.resize((new_w, new_h), Image.LANCZOS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trade\\-off:** Look, smaller images save money but they might hurt OCR accuracy on tiny fonts. I've played with `max_long_edge` a lot, and 2048 seems to work for most invoices. But honestly, you might need to tweak this based on what you're dealing with.\n\n## Preprocess Images for OCR\n\nMake them more readable with grayscale, thresholding, and deskew:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\nimport numpy as np\n\ndef preprocess_for_ocr(pil_img: Image.Image) -> Image.Image:\n    \"\"\"Preprocess image for OCR by applying grayscale, thresholding, and deskew.\"\"\"\n    img = np.array(pil_img)\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                               cv2.THRESH_BINARY, 35, 11)\n    \n    # Deskew via moments (guard against empty image)\n    coords = np.column_stack(np.where(th > 0))\n    if len(coords) == 0:\n        return Image.fromarray(th)\n    \n    angle = cv2.minAreaRect(coords)[-1]\n    if angle < -45:\n        angle = -(90 + angle)\n    else:\n        angle = -angle\n    \n    (h, w) = th.shape[:2]\n    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n    rotated = cv2.warpAffine(th, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n    return Image.fromarray(rotated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Adaptive thresholding is great for uneven lighting. Deskew fixes rotation issues. And that guard? Prevents crashes when you accidentally feed it a blank image. Ask me how I know that one.\n\n## Run Tesseract OCR\n\nOur fallback text extraction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytesseract\n\ndef ocr_extract_text(pil_img: Image.Image) -> str:\n    \"\"\"Extract text from an image using Tesseract OCR.\"\"\"\n    return pytesseract.image_to_string(pil_img, lang=\"eng\", config=\"--psm 6 --oem 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** `--psm 6` assumes you've got uniform text blocks. `--oem 1` uses LSTM which, honestly, gives better accuracy most of the time. I tried all the different modes and this combo just works.\n\n## Convert Image to Data URL\n\nEncode the image for the Vision API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\nfrom io import BytesIO\n\ndef pil_to_data_url(img: Image.Image) -> str:\n    \"\"\"Convert a PIL image to a data URL.\"\"\"\n    buf = BytesIO()\n    img.save(buf, format=\"PNG\")\n    b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n    return f\"data:image/png;base64,{b64}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define System Prompt and Few\\-Shot Examples\n\nGuide the model with clear instructions and a solid example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = (\n    \"You are a careful invoicing parser. Extract fields strictly as JSON. \"\n    \"Do not include any text outside the JSON. If a value is missing, infer cautiously \"\n    \"from context; otherwise omit the field. Use ISO 8601 dates (YYYY-MM-DD) and ISO 4217 currency.\"\n)\n\ndef schema_summary(schema: dict) -> str:\n    \"\"\"Summarize required fields and types for the prompt.\"\"\"\n    req = schema.get(\"required\", [])\n    props = schema.get(\"properties\", {})\n    lines = [\"Required fields and types:\"]\n    for k in req:\n        t = props.get(k, {}).get(\"type\", \"any\")\n        lines.append(f\"- {k}: {t}\")\n    lines.append(\"Line item fields: description (string), quantity (number), unit_price (number), line_total (number).\")\n    return \"\\n\".join(lines)\n\nFEW_SHOT_USER = (\n    \"Example: Extract JSON from this text-only invoice:\\n\"\n    \"ACME Corp\\nInvoice INV-123\\nDate 2024-06-01\\n\"\n    \"1x Widget A @ 10.00\\n2x Widget B @ 5.00\\nSubtotal 20.00\\nTax 2.00\\nTotal 22.00\\n\"\n)\n\nFEW_SHOT_ASSISTANT = \"\"\"{\n  \"vendor\": \"ACME Corp\",\n  \"invoice_number\": \"INV-123\",\n  \"invoice_date\": \"2024-06-01\",\n  \"currency\": \"USD\",\n  \"subtotal\": 20.0,\n  \"tax\": 2.0,\n  \"total\": 22.0,\n  \"line_items\": [\n    {\"description\": \"Widget A\", \"quantity\": 1, \"unit_price\": 10.0, \"line_total\": 10.0},\n    {\"description\": \"Widget B\", \"quantity\": 2, \"unit_price\": 5.0, \"line_total\": 10.0}\n  ]\n}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Few\\-shot examples are gold. They show the model exactly what format you want and really cut down on hallucinations. I used to skip this step. Big mistake.\n\n## Call GPT\\-4o Vision with Retry Logic\n\nExtract invoice data from the image, with automatic retries when things go wrong:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\nimport time\nfrom openai import OpenAI\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\nclient = OpenAI()\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef call_gpt4o_vision(img: Image.Image, schema: dict):\n    \"\"\"Call GPT-4o Vision API to extract invoice data as JSON.\"\"\"\n    data_url = pil_to_data_url(img)\n    start = time.time()\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": \"Extract an invoice as JSON. Follow this contract:\\n\" + schema_summary(schema)},\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n                ]\n            }\n        ],\n        temperature=0.2\n    )\n    latency_ms = int((time.time() - start) * 1000)\n    text = resp.choices[0].message.content\n    usage = resp.usage\n    request_id = resp.id\n    return json.loads(text), latency_ms, usage, request_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** That `response_format=json_object` is key. Forces JSON output every time. And the retry logic? Handles those annoying transient API errors that always seem to happen at the worst possible moment.\n\n## Validate Against JSON Schema\n\nCollect all the validation errors for targeted repair:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jsonschema import Draft202012Validator, ValidationError\n\ndef validate_against_schema(data: dict, schema: dict):\n    \"\"\"Validate data against the JSON schema and return all errors.\"\"\"\n    validator = Draft202012Validator(schema)\n    errors = []\n    for e in validator.iter_errors(data):\n        path = \"/\".join(map(str, e.path)) or \"$\"\n        errors.append(f\"path={path}: {e.message}\")\n    return len(errors) == 0, errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Getting all errors at once is important. Gives the model the full picture of what needs fixing instead of playing whack\\-a\\-mole with individual issues.\n\n## Repair JSON with Targeted Feedback\n\nSend those validation errors back to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef repair_with_gpt(img: Image.Image, schema: dict, prev: dict, errors: list):\n    \"\"\"Repair JSON data using GPT-4o Vision based on validation errors.\"\"\"\n    data_url = pil_to_data_url(img)\n    prompt = \"The previous JSON failed validation. Fix strictly per errors:\\n\" + \"\\n\".join(f\"- {err}\" for err in errors)\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"text\", \"text\": \"Original image for reference:\"},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n            ]},\n            {\"role\": \"user\", \"content\": f\"Previous JSON:\\n{json.dumps(prev, ensure_ascii=False)}\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ],\n        temperature=0.1\n    )\n    fixed = json.loads(resp.choices[0].message.content)\n    return fixed, resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Lower temperature (0\\.1\\) keeps the model from getting too creative during repairs. And showing the original image again? Keeps everything in context. The model needs to see what it's working with.\n\n## Check Numeric Consistency\n\nMake sure the math actually adds up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def numeric_consistency_ok(data: dict, tol: float = 0.05):\n    \"\"\"Check if numeric fields in the data are consistent within a tolerance.\"\"\"\n    try:\n        subtotal = float(data.get(\"subtotal\", 0))\n        tax = float(data.get(\"tax\", 0))\n        total = float(data.get(\"total\", 0))\n        li_sum = sum(float(it.get(\"line_total\", 0)) for it in data.get(\"line_items\", []))\n        return (abs(li_sum - subtotal) <= tol and\n                abs(subtotal + tax - total) <= tol)\n    except Exception:\n        return False\n\ndef build_numeric_errors(data: dict):\n    \"\"\"Build error messages for numeric inconsistencies.\"\"\"\n    subtotal = data.get(\"subtotal\", None)\n    tax = data.get(\"tax\", None)\n    total = data.get(\"total\", None)\n    li_sum = sum(float(it.get(\"line_total\", 0)) for it in data.get(\"line_items\", []))\n    msgs = []\n    msgs.append(f\"Sum(line_items.line_total)={li_sum}, subtotal={subtotal}, tax={tax}, total={total}.\")\n    msgs.append(\"Enforce: sum(line_items) â‰ˆ subtotal; subtotal + tax â‰ˆ total; update fields minimally to satisfy.\")\n    return msgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** The tolerance handles rounding issues. And those explicit error messages? They tell the model exactly what arithmetic to fix. I've seen some wild math from these models when they're left to their own devices.\n\n## Fallback to OCR and Text\\-Only Extraction\n\nWhen vision fails, preprocess and extract from text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef call_gpt_text_only(ocr_text: str, schema: dict, extra_instructions: str = \"\"):\n    \"\"\"Call GPT-4o using OCR text to extract invoice data as JSON.\"\"\"\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\"role\": \"user\", \"content\": \"Extract invoice JSON strictly per schema summary:\\n\" + schema_summary(schema)},\n            {\"role\": \"user\", \"content\": f\"Invoice text:\\n{ocr_text}\"},\n            {\"role\": \"user\", \"content\": extra_instructions} if extra_instructions else {\"role\": \"user\", \"content\": \"\"}\n        ],\n        temperature=0.2\n    )\n    data = json.loads(resp.choices[0].message.content)\n    return data, resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Passing numeric errors separately keeps the invoice text clean. Makes the repair signal much clearer. This whole fallback mechanism saved my bacon more than once.\n\n## Persist Results to Postgres\n\nUpsert the document and replace line items idempotently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upsert_document(conn, doc_hash: str, filename: str, data: dict):\n    \"\"\"Upsert document data into Postgres and replace line items.\"\"\"\n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            INSERT INTO documents (document_hash, filename, vendor, invoice_number, invoice_date, currency,\n                                   subtotal, tax, total, data, created_at, updated_at)\n            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())\n            ON CONFLICT (document_hash) DO UPDATE SET\n                filename = EXCLUDED.filename,\n                vendor = EXCLUDED.vendor,\n                invoice_number = EXCLUDED.invoice_number,\n                invoice_date = EXCLUDED.invoice_date,\n                currency = EXCLUDED.currency,\n                subtotal = EXCLUDED.subtotal,\n                tax = EXCLUDED.tax,\n                total = EXCLUDED.total,\n                data = EXCLUDED.data,\n                updated_at = NOW()\n            RETURNING id\n        \"\"\", (\n            doc_hash, filename,\n            data.get(\"vendor\"),\n            data.get(\"invoice_number\"),\n            data.get(\"invoice_date\"),\n            data.get(\"currency\"),\n            data.get(\"subtotal\"),\n            data.get(\"tax\"),\n            data.get(\"total\"),\n            json.dumps(data),\n        ))\n        doc_id = cur.fetchone()[0]\n        \n        # Replace line items\n        cur.execute(\"DELETE FROM line_items WHERE document_id = %s\", (doc_id,))\n        for idx, it in enumerate(data.get(\"line_items\", []), start=1):\n            cur.execute(\"\"\"\n                INSERT INTO line_items (document_id, line_number, description, quantity, unit_price, line_total)\n                VALUES (%s, %s, %s, %s, %s, %s)\n            \"\"\", (\n                doc_id, idx,\n                it.get(\"description\"),\n                it.get(\"quantity\"),\n                it.get(\"unit_price\"),\n                it.get(\"line_total\")\n            ))\n    conn.commit()\n    return doc_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** `ON CONFLICT` makes sure re\\-runs just update existing records. And deleting then reinserting line items? Keeps everything in sync. Not the most elegant solution maybe, but it works reliably.\n\n## Log Processing Metadata\n\nTrack everything for observability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_processing(conn, doc_hash: str, request_id: str, status: str, latency_ms: int,\n                   usage=None, error_message: str = None):\n    \"\"\"Log processing details into the database for observability.\"\"\"\n    # Sanitize error message to avoid logging large payloads\n    if error_message and len(error_message) > 500:\n        error_message = error_message[:500] + \"... (truncated)\"\n    \n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            INSERT INTO processing_logs (document_hash, request_id, status, latency_ms,\n                                         prompt_tokens, completion_tokens, total_tokens, error_message, created_at)\n            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW())\n        \"\"\", (\n            doc_hash,\n            request_id,\n            status,\n            latency_ms,\n            getattr(usage, \"prompt_tokens\", None) if usage else None,\n            getattr(usage, \"completion_tokens\", None) if usage else None,\n            getattr(usage, \"total_tokens\", None) if usage else None,\n            error_message\n        ))\n    conn.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Truncating error messages is smart. Prevents PII leakage and keeps your logs from getting huge. Learned that one after accidentally logging full invoice text for a week.\n\n## Orchestrate the End\\-to\\-End Pipeline\n\nProcess a single invoice file through all the steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n\ndef process_invoice_file(file_path: str):\n    \"\"\"Process an invoice file through the full pipeline.\"\"\"\n    doc_hash = compute_document_hash(file_path)\n    images = file_to_images(file_path)\n    first_img = resize_image_for_vision(images[0])\n\n    data = None\n    usage = None\n    request_id = None\n    status = \"ok\"\n    error_message = None\n    start_time = time.time()\n\n    try:\n        # Attempt Vision extraction\n        data, _, usage, request_id = call_gpt4o_vision(first_img, invoice_schema)\n        ok, errs = validate_against_schema(data, invoice_schema)\n        \n        # Repair if validation fails\n        if not ok:\n            data, repair_resp = repair_with_gpt(first_img, invoice_schema, data, errs)\n            usage = repair_resp.usage\n            request_id = repair_resp.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n\n        # Numeric consistency repair\n        if ok and not numeric_consistency_ok(data):\n            numeric_errs = build_numeric_errors(data)\n            data, repair_resp2 = repair_with_gpt(first_img, invoice_schema, data, numeric_errs)\n            usage = repair_resp2.usage\n            request_id = repair_resp2.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n\n        # OCR fallback\n        if not ok:\n            pre = preprocess_for_ocr(first_img)\n            ocr_text = ocr_extract_text(pre)\n            data, text_resp = call_gpt_text_only(ocr_text, invoice_schema)\n            usage = text_resp.usage\n            request_id = text_resp.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n            \n            # Numeric repair for OCR path\n            if ok and not numeric_consistency_ok(data):\n                numeric_errs = build_numeric_errors(data)\n                data, repair_resp3 = call_gpt_text_only(ocr_text, invoice_schema, \"\\n\".join(numeric_errs))\n                usage = repair_resp3.usage\n                request_id = repair_resp3.id\n                ok, errs = validate_against_schema(data, invoice_schema)\n\n        if not ok:\n            status = \"failed\"\n            error_message = \"Validation failed after OCR fallback: \" + \"; \".join(errs)\n\n        # Persist if successful\n        latency_ms = int((time.time() - start_time) * 1000)\n        if status == \"ok\":\n            with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n                upsert_document(conn, doc_hash, os.path.basename(file_path), data)\n                log_processing(conn, doc_hash, request_id, status, latency_ms, usage, None)\n        else:\n            with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n                log_processing(conn, doc_hash, request_id, status, latency_ms, usage, error_message)\n\n        return {\"file\": file_path, \"hash\": doc_hash, \"status\": status, \"errors\": None if status == \"ok\" else error_message}\n\n    except Exception as e:\n        status = \"error\"\n        error_message = str(e)\n        latency_ms = int((time.time() - start_time) * 1000)\n        with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n            log_processing(conn, doc_hash, request_id, status, latency_ms, usage, error_message)\n        return {\"file\": file_path, \"hash\": doc_hash, \"status\": status, \"errors\": error_message}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Tracking `start_time` right at the top captures true end\\-to\\-end latency. Each path, whether it's vision, repair, or OCR, updates usage and `request_id` for accurate logging. You need this visibility when things go sideways.\n\n## Run the Pipeline on Sample Files\n\nProcess everything in your input directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dir = \"/content/invoices\"\nfiles = sorted([p for p in glob.glob(os.path.join(input_dir, \"*\")) if os.path.isfile(p)])\n\nresults = []\nfor f in files:\n    res = process_invoice_file(f)\n    print(res)\n    results.append(res)\n\nsummary = {\n    \"processed\": len(results),\n    \"ok\": sum(1 for r in results if r[\"status\"] == \"ok\"),\n    \"failed\": sum(1 for r in results if r[\"status\"] == \"failed\"),\n    \"error\": sum(1 for r in results if r[\"status\"] == \"error\"),\n}\nprint(\"Summary:\", summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Idempotency\n\nRun it again and make sure you don't get duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count documents before re-run\nwith psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT COUNT(*) FROM documents\")\n        count_before = cur.fetchone()[0]\n\n# Re-run processing\nfor f in files:\n    res = process_invoice_file(f)\n    print(\"Re-run:\", res)\n\n# Count documents after re-run\nwith psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT COUNT(*) FROM documents\")\n        count_after = cur.fetchone()[0]\n\nprint(f\"Documents before: {count_before}, after: {count_after}\")\nassert count_before == count_after, \"Idempotency check failed: duplicate documents created\"\nprint(\"âœ“ Idempotency verified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** If the counts are equal, you know `ON CONFLICT` is working. Only thing that should change is `updated_at`. This check has caught so many bugs for me.\n\n## Query and Inspect Results\n\nTake a look at what you extracted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            SELECT id, filename, vendor, invoice_number, invoice_date, currency, subtotal, tax, total\n            FROM documents ORDER BY id DESC LIMIT 5\n        \"\"\")\n        print(\"Documents:\")\n        for row in cur.fetchall():\n            print(row)\n\n        cur.execute(\"\"\"\n            SELECT d.invoice_number, li.line_number, li.description, li.quantity, li.unit_price, li.line_total\n            FROM line_items li\n            JOIN documents d ON li.document_id = d.id\n            ORDER BY d.id DESC, li.line_number ASC\n            LIMIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wrapping Up\n\nSo there you have it. A complete invoice extraction pipeline that actually handles the messy reality of real\\-world documents. It's not perfect, nothing ever is, but it's robust enough to handle most of what you'll throw at it. The combination of vision AI with OCR fallback, strict validation, and automatic repair gives you something you can actually rely on.\n\nThe best part? You can extend this in so many ways. Add support for multiple pages, integrate with your accounting system, build a nice UI on top. But start here, get this working, and then iterate. That's how I've always approached these systems, and it's served me well."
      ]
    }
  ],
  "metadata": {
    "title": "Invoice Data Extraction: How to Get JSON via GPT-4o Vision",
    "description": "Ship a production-ready, template-less invoice data extractor: jsonschema-validated JSON, retryable GPT-4o Vision, OCR fallback, and idempotent Postgres upserts with logs.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}