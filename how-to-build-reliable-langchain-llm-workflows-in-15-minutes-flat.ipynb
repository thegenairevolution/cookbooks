{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build Reliable LangChain LLM Workflows in 15 Minutes Flat\n\n**Description:** Get hands-on with LangChain: install, configure models, build prompt-driven chains, and parse structured outputsâ€”launch reliable Python LLM workflows fast today.\n\n**ðŸ“– Read the full article:** [How to Build Reliable LangChain LLM Workflows in 15 Minutes Flat](https://blog.thegenairevolution.com/article/how-to-build-reliable-langchain-llm-workflows-in-15-minutes-flat)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You want a fast path to a reliable LLM workflow. In 15 minutes, you'll build a production\\-ready LLM workflow in Python using LangChain that outputs strict JSON for downstream systems. Setup friction and unclear abstractions stall delivery. Brittle parsing breaks downstream systems. This guide shows you how to build a chain that turns customer emails into strict JSON dictionaries ready for routing, so tickets get routed, refunds get initiated, and analytics get updated without manual intervention. You'll need Python 3\\.9\\+, an OpenAI account with API access, and basic familiarity with pip and environment variables.\n\n## Why Use LangChain for This Problem\n\nLangChain provides composable abstractions that let you connect prompts, models, and parsers into reusable chains. You avoid boilerplate for message formatting, retry logic, and output parsing. The library's LCEL (LangChain Expression Language) syntax makes chains readable and testable. You can swap models, adjust prompts, and add validation without rewriting integration code.\n\nNow, you could call the OpenAI SDK directly or use something like LlamaIndex. Direct SDK calls give you full control but require manual message formatting, error handling, and parsing logic. It's a lot of work for something that should be simple. LlamaIndex excels at retrieval\\-augmented generation but honestly adds complexity if you only need prompt\\-to\\-structured\\-output workflows. LangChain strikes a nice balance. It handles the plumbing while keeping your code explicit and maintainable.\n\n## Core Concepts for This Use Case\n\n**Runnables and chains.** A runnable is any component you can invoke with input and get output. Chains are runnables composed with the pipe operator. In this workflow, you chain a prompt template, an LLM, and a parser into a single callable unit. Simple as that.\n\n**Prompt templates.** Templates let you parameterize system and user messages. You inject variables like persona and user input at runtime. This keeps prompts version\\-controlled and testable. In the email extraction workflow, the template injects format instructions and the email text. For deeper guidance on crafting prompts that elicit reasoning and precision, see our [techniques for prompting reasoning models for clear, accurate answers](/article/how-to-prompt-reasoning-models-for-clear-accurate-answers-techniques-examples-2).\n\n**Structured output parsers.** Parsers enforce a schema on the model's response. You define fields and types, and the parser validates the JSON. StructuredOutputParser enforces the email\\-to\\-JSON mapping we route to support systems. If the model returns invalid JSON, the parser raises an exception you can catch and retry. This is where things get interesting.\n\n**Messages.** LangChain uses message objects (SystemMessage, HumanMessage, AIMessage) to represent conversation turns. This makes multi\\-turn context explicit and portable across models. To level up multi\\-turn performance with examples and patterning, explore [in\\-context learning techniques to boost LLM accuracy](/article/the-magic-of-in-context-learning-teach-your-llm-on-the-fly-3).\n\n## Setup\n\nInstall the required packages. Run this command in your terminal or notebook. If you want a quick refresher on the architectures behind modern LLMs, read our [ultimate guide to transformer models for LLM practitioners](/article/transformers-demystifying-the-magic-behind-large-language-models-2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-community langchain-openai openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load your API keys securely. Never hardcode keys in your code. Use Colab secrets or environment variables. This snippet loads keys from Colab secrets and raises an error if any are missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom google.colab import userdata\nfrom google.colab.userdata import SecretNotFoundError\n\nkeys = [\"OPENAI_API_KEY\", \"ANTHROPIC_API_KEY\"]\nmissing = []\nfor k in keys:\n    value = None\n    try:\n        value = userdata.get(k)\n    except SecretNotFoundError:\n        pass\n\n    os.environ[k] = value if value is not None else \"\"\n\n    if not os.environ[k]:\n        missing.append(k)\n\nif missing:\n    raise EnvironmentError(f\"Missing keys: {', '.join(missing)}. Add them in Colab â†’ Settings â†’ Secrets.\")\n\nprint(\"All keys loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify imports and environment. This block ensures your OpenAI key is present and imports the core LangChain components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n\nassert os.getenv(\"OPENAI_API_KEY\"), \"Set OPENAI_API_KEY in your Colab secrets\"\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import SystemMessage, HumanMessage, AIMessage\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.output_parsers import ResponseSchema, StructuredOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instantiate the model. Use temperature 0 for deterministic output and set max\\_tokens to control cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(\n    model=\"gpt-4o-mini\",\n    temperature=0,\n    max_tokens=300,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the model with a single prompt. This verifies connectivity and credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "msg = llm.invoke(\"Summarize why consistent JSON outputs help downstream systems.\")\nprint(type(msg))\nprint(msg.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect the response metadata. This shows token usage and finish reason."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Response metadata:\", getattr(msg, \"response_metadata\", {}))\nprint(\"Usage metadata:\", getattr(msg, \"usage_metadata\", {}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the Tool in Practice\n\nBuild a multi\\-turn conversation. Use explicit message roles to control context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n    SystemMessage(content=\"You are a concise assistant that extracts key facts.\"),\n    HumanMessage(content=\"I purchased earbuds last week. The left bud is dead.\"),\n    AIMessage(content=\"Noted. A device failure on the left earbud.\"),\n    HumanMessage(content=\"What information would you need to process a warranty claim?\")\n]\n\nreply = llm.invoke(messages)\nprint(reply.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a prompt template with variables. This lets you inject persona and user input at runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"{persona}\"),\n        (\"human\", \"{user_input}\")\n    ]\n)\n\nrendered = prompt.invoke({\n    \"persona\": \"You are a helpful customer support assistant.\",\n    \"user_input\": \"Customer reports a faulty left earbud after 7 days. Next step?\"\n})\nprint(rendered.to_messages())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actually, let me emphasize something here. Parameterizing prompts and enforcing structured outputs are crucial for reliability. For more strategies on building robust LLM features and reducing errors in production, see our guide on [prompt engineering with LLM APIs for reliable outputs](/article/prompt-engineering-with-llm-apis-how-to-get-reliable-outputs-4).\n\nCompose a chain with LCEL. This connects the prompt and model into a reusable workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain = prompt | llm\n\nresp = chain.invoke({\n    \"persona\": \"You are a helpful customer support assistant.\",\n    \"user_input\": \"The customer wants a refund for defective earbuds. What should we do?\"\n})\nprint(resp.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define response schemas for structured fields. This guides the model to output specific fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "schemas = [\n    ResponseSchema(\n        name=\"type\",\n        description=\"One of complaint, inquiry, feedback.\"\n    ),\n    ResponseSchema(\n        name=\"product\",\n        description=\"Product or service mentioned, string.\"\n    ),\n    ResponseSchema(\n        name=\"action\",\n        description=\"Recommended action like refund, replace, clarify, route_to_support.\"\n    ),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add a StructuredOutputParser and generate format instructions. This enforces strict JSON output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parser = StructuredOutputParser.from_response_schemas(schemas)\nformat_instructions = parser.get_format_instructions()\nprint(format_instructions[:200], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build the full prompt\\-to\\-model\\-to\\-parser chain. This extracts structured fields from customer emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extraction_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You extract structured fields from customer emails. \"\n            \"Return JSON that strictly follows these rules. {format_instructions}\"\n        ),\n        (\"human\", \"Email:\\n{email}\")\n    ]\n)\n\nextraction_chain = extraction_prompt | llm | parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run customer emails through the extraction chain. This prints parsed Python dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "emails = [\n    \"Hi, my left earbud stopped working after a week. I want a refund please.\",\n    \"Hello, can you tell me if the Model X earbuds support wireless charging?\",\n    \"Just wanted to say the new firmware fixed my microphone issue. Thanks.\"\n]\n\nfor e in emails:\n    result = extraction_chain.invoke({\n        \"email\": e,\n        \"format_instructions\": format_instructions\n    })\n    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validate schema coverage and values. This ensures model output matches expectations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_result(d):\n    assert isinstance(d, dict)\n    assert d[\"type\"] in {\"complaint\", \"inquiry\", \"feedback\"}\n    assert isinstance(d[\"product\"], str)\n    assert isinstance(d[\"action\"], str)\n\nfor e in emails:\n    d = extraction_chain.invoke({\"email\": e, \"format_instructions\": format_instructions})\n    validate_result(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run and Evaluate\n\nInspect usage and latency without parsing. This helps you evaluate cost and performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from time import perf_counter\n\nraw_chain = extraction_prompt | llm\n\nstart = perf_counter()\nraw_msg = raw_chain.invoke({\"email\": emails[0], \"format_instructions\": format_instructions})\nelapsed = perf_counter() - start\n\nprint(\"Latency seconds:\", round(elapsed, 3))\nprint(\"Usage:\", getattr(raw_msg, \"usage_metadata\", {}))\n\nparsed = parser.invoke(raw_msg)\nprint(parsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build a reusable function for production calls. This includes validation and usage tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_email_fields(email: str) -> dict:\n    raw = raw_chain.invoke({\"email\": email, \"format_instructions\": format_instructions})\n    usage = getattr(raw, \"usage_metadata\", {})\n    parsed = parser.invoke(raw)\n    validate_result(parsed)\n    return {\"data\": parsed, \"usage\": usage}\n\nprint(extract_email_fields(\"The Model X case will not charge. Need a replacement.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add a persona layer for domain\\-specific language. This tailors the model's tone and vocabulary. I've found this particularly useful when dealing with industry\\-specific terminology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "persona = \"You are a support triage assistant for consumer audio devices.\"\npersona_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", persona + \" Return strict JSON. {format_instructions}\"),\n        (\"human\", \"Email:\\n{email}\")\n    ]\n)\npersona_chain = persona_prompt | llm | parser\n\nprint(persona_chain.invoke({\"email\": emails[1], \"format_instructions\": format_instructions}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the workflow with your own examples. Include edge cases to test robustness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_emails = [\n    \"Order 1234. Model X earbuds arrived scratched. I want a refund.\",\n    \"Do the Model Y earbuds pair with two phones at once?\",\n    \"Love the sound on Model Z. Battery could be better, just feedback.\"\n]\n\nfor e in my_emails:\n    print(extraction_chain.invoke({\"email\": e, \"format_instructions\": format_instructions}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Track basic telemetry for each invocation. This returns latency, usage, and parsed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def timed_invoke(email):\n    import time\n    t0 = time.perf_counter()\n    raw = raw_chain.invoke({\"email\": email, \"format_instructions\": format_instructions})\n    dt = time.perf_counter() - t0\n    usage = getattr(raw, \"usage_metadata\", {})\n    return dt, usage, parser.invoke(raw)\n\nfor e in emails:\n    dt, usage, data = timed_invoke(e)\n    print({\"latency_s\": round(dt, 3), \"usage\": usage, \"data\": data})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handle invalid JSON gracefully with retries. This uses a corrective prompt if parsing fails. Here's the thing, models sometimes return malformed JSON, and you need to be ready for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.output_parsers import OutputParserException\n\ndef safe_extract(email, max_retries=1):\n    for attempt in range(max_retries + 1):\n        try:\n            return extraction_chain.invoke({\"email\": email, \"format_instructions\": format_instructions})\n        except OutputParserException:\n            corrective = ChatPromptTemplate.from_messages(\n                [\n                    (\"system\", \"Return valid JSON only. Do not include commentary. {format_instructions}\"),\n                    (\"human\", \"Email:\\n{email}\")\n                ]\n            )\n            retry_chain = corrective | llm | parser\n            if attempt < max_retries:\n                result = retry_chain.invoke({\"email\": email, \"format_instructions\": format_instructions})\n                return result\n            raise\n\nprint(safe_extract(\"Refund me please. Model X left earbud broke in a week.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expand the schema when business needs change. This adds an urgency field based on sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "schemas_extended = schemas + [\n    ResponseSchema(name=\"urgency\", description=\"low, medium, high based on sentiment and urgency cues.\")\n]\nparser_ext = StructuredOutputParser.from_response_schemas(schemas_extended)\nfmt_ext = parser_ext.get_format_instructions()\n\nprompt_ext = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"Extract fields and urgency. Return strict JSON. {format_instructions}\"),\n        (\"human\", \"Email:\\n{email}\")\n    ]\n)\nchain_ext = prompt_ext | llm | parser_ext\n\nprint(chain_ext.invoke({\"email\": emails[0], \"format_instructions\": fmt_ext}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add minimal unit tests for the extraction chain. This validates field values and types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_extraction():\n    sample = \"Left earbud on Model X stopped working. Please replace.\"\n    d = extraction_chain.invoke({\"email\": sample, \"format_instructions\": format_instructions})\n    assert d[\"type\"] in {\"complaint\", \"inquiry\", \"feedback\"}\n    assert isinstance(d[\"product\"], str)\n    assert d[\"action\"] in {\"refund\", \"replace\", \"clarify\", \"route_to_support\"}\n\ntest_extraction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use prompt fixtures for reproducibility. This ensures regression testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixtures = [\n    {\n        \"email\": \"Model X case not charging. Need a replacement.\",\n        \"expect_type\": {\"complaint\"},\n    },\n    {\n        \"email\": \"Do Model Y earbuds support USB C charging?\",\n        \"expect_type\": {\"inquiry\"},\n    },\n]\n\nfor fx in fixtures:\n    d = extraction_chain.invoke({\"email\": fx[\"email\"], \"format_instructions\": format_instructions})\n    assert d[\"type\"] in fx[\"expect_type\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Batch processing with simple loops. This processes multiple emails in one pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = [extraction_chain.invoke({\"email\": e, \"format_instructions\": format_instructions}) for e in emails]\nprint(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Swap models with one line changes. This lets you experiment with different models. In a previous role, I found this incredibly useful when comparing GPT\\-4 against Claude for specific extraction tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_alt = ChatOpenAI(model=\"gpt-4o\", temperature=0, max_tokens=300)\nextraction_chain_alt = extraction_prompt | llm_alt | parser\n\nprint(extraction_chain_alt.invoke({\"email\": emails[2], \"format_instructions\": format_instructions}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Version prompts and parsers in code. This enables traceability and rollback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROMPT_VERSION = \"v1.2\"\nSCHEMA_VERSION = \"v1.1\"\n\nprint({\"prompt_version\": PROMPT_VERSION, \"schema_version\": SCHEMA_VERSION})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lightweight configuration with environment variables. This lets you change model and temperature without code edits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"gpt-4o-mini\")\nTEMP = float(os.getenv(\"TEMP\", \"0\"))\nllm_cfg = ChatOpenAI(model=MODEL_NAME, temperature=TEMP, max_tokens=300)\ncfg_chain = extraction_prompt | llm_cfg | parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sample test cases to try now. These cover complaints, inquiries, and feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cases = [\n    \"I love the sound on Model X, but the right bud randomly disconnects. Can you replace it?\",\n    \"Do Model Y earbuds work with iOS 17? If yes, how to pair?\",\n    \"Great update, pairing is faster now. Just a note for your team.\"\n]\n\nfor c in cases:\n    print(cfg_chain.invoke({\"email\": c, \"format_instructions\": format_instructions}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nYou built a production\\-ready LLM workflow that turns customer emails into strict JSON dictionaries. You used LangChain's prompt templates, structured output parsers, and LCEL chains to keep the code readable and testable. You validated outputs, tracked token usage, and handled parsing errors with retries.\n\nThis approach stays maintainable because prompts, schemas, and models are decoupled. You can version prompts, swap models, and extend schemas without rewriting integration logic. That's the real power here.\n\nIf your workflow requires grounding responses in external knowledge, consider integrating retrieval\\-augmented generation (RAG). Our [ultimate guide to vector store retrieval for RAG systems](/article/rag-101-build-an-index-run-semantic-search-and-use-langchain-to-automate-it) explains how to implement semantic search and chunking to minimize hallucinations and boost reliability.\n\nAnd if you want to go beyond prompt\\-driven chains and customize your LLM's behavior at a deeper level, consider learning how to fine\\-tune models yourself. Our [step\\-by\\-step guide to fine\\-tuning large language models](/article/fine-tuning-large-language-models-a-step-by-step-guide-2025-5) walks you through dataset preparation, training, and evaluation using Hugging Face tools."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build Reliable LangChain LLM Workflows in 15 Minutes Flat",
    "description": "Get hands-on with LangChain: install, configure models, build prompt-driven chains, and parse structured outputsâ€”launch reliable Python LLM workflows fast today.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}