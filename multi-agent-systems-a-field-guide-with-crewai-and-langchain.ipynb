{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** Multi-Agent Systems: A Field Guide with CrewAI and LangChain\n\n**Description:** Build fast, controllable multi-agent systems using CrewAI and LangChain with task granularity, Pydantic I/O, parallel execution, and focused agents today.\n\n**ðŸ“– Read the full article:** [Multi-Agent Systems: A Field Guide with CrewAI and LangChain](https://blog.thegenairevolution.com/article/multi-agent-systems-a-field-guide-with-crewai-and-langchain)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building multi\\-agent systems with LLMs isn't like building regular software. It's actually much closer to doing data science. You form a hypothesis, test it out, tweak your setup, and repeat. Over and over again. If you're expecting your agents and tasks to work perfectly right out of the gate, well, you're going to be disappointed.\n\nI've spent the past few months building and refining agent\\-based systems, and I've learned that using CrewAI and LangChain makes a massive difference. Not just in how quickly I can build, but in how easy it is to experiment and iterate. If you're looking for a [step\\-by\\-step guide to building multi\\-agent AI systems with CrewAI](/article/how-to-build-multi-agent-ai-systems-with-crewai-and-yaml-2), we cover reusable patterns, guardrails, and YAML\\-first workflows.\n\nThis post shares the practical lessons that have actually worked for me. It's not a tutorial or a feature tour. Think of it more as a field guide. How to structure tasks, how to keep agents focused, how to speed up execution, and how to keep your system from completely falling apart as it grows. Hopefully, this saves you some time, frustration, and more than a few late nights.\n\n## Start with Tasks, Keep Them Small\n\n### Clearly Define and Structure Your Tasks\n\nWhen you're building multi\\-agent systems, you need to start by clearly defining your tasks. Writing detailed, step\\-by\\-step instructions helps clarify what you're trying to accomplish and what you expect from each agent. What I quickly realized is that tasks tend to become overly complex, especially when you try to do too much at once.\n\n### Avoid Task Overload\n\nHere's a practical challenge I kept running into. When tasks contain more than a handful of steps, even with those massive context windows we have now, your LLM\\-based agents start dropping essential instructions. It's like they just forget what they're supposed to be doing halfway through. This loss of clarity is a clear signal that your tasks are trying to do too much and need to be simplified.\n\n### Breaking Down Tasks\n\nWhat works best for me is keeping tasks concise. I try to limit them to around 3 or 4 clear steps each. If I notice a task getting too complex, I split it up into smaller subtasks. For instance, instead of combining user intent classification with immediate task execution in one go, I separate these processes. It makes everything clearer and more accurate. By breaking down large tasks, you really do improve agent performance, accuracy, and manageability significantly.\n\n### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# What not to do\ngod_task:\n  description: >\n    Analyze the user query, classify the intent, extract relevant entities,\n    query the knowledge base, generate a markdown response, ask for clarification \n    if needed, log the request for analytics, and refresh the cache if the user is \n    a premium member.\n  expected_output: >\n    A complete markdown response to the user query, with intent classified,\n    relevant entities extracted, cache refreshed (if needed), and analytics updated.\n  agent: TBD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# What works\nclassify_intent:\n  description: >\n    Analyze the user's input and classify it into a predefined intent category\n    (e.g., information request, action request, greeting). If the intent is unclear,\n    ask a clarifying question before proceeding.\n  expected_output: >\n    A JSON object with the intent category and any follow-up question if clarification is needed.\n  agent: TBD\n\nextract_entities:\n  description: >\n    Based on the classified intent, extract any relevant entities from the \n    user's input. These may include product names, locations and dates.\n  expected_output: >\n    A JSON object containing the extracted entities as key-value pairs.\n  agent: TBD\n\nretrieve_and_respond:\n  description: >\n    Using the classified intent and extracted entities, search the appropriate \n    data sources and generate a markdown-formatted response that directly \n    answers the user query.\n  expected_output: >\n    A well-formatted markdown answer that is accurate and relevant to the user query.\n  agent: TBD\n\nlog_and_refresh:\n  description: >\n    If the user is a premium member, log the query metadata to the analytics system\n    and refresh the corresponding cache entries. This task is optional and should \n    run independently.\n  expected_output: >\n    A status report indicating whether analytics were logged and cache was refreshed.\n  agent: TBD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Pydantic Models to Control Inputs and Outputs\n\n### The Role of Structured Data in Multi\\-Agent Systems\n\nOnce you've got your tasks defined and agents focused, the next challenge is maintaining consistent and reliable communication between them. This is where structured input and output becomes absolutely crucial. Without clearly defined data formats, information gets lost, misinterpreted, or becomes too ambiguous for the next agent in the chain to handle properly. I learned this the hard way.\n\n### Why Pydantic Makes a Difference\n\nUsing Pydantic models helps enforce what I like to think of as a shared contract between tasks. For more on [best practices for prompt engineering and reliable LLM outputs](/article/prompt-engineering-with-llm-apis-how-to-get-reliable-outputs-3), including how to structure prompts and enforce output formats, check out our in\\-depth guide. These models basically act as schemas that define exactly what an agent expects and what it will return. This is especially helpful when you're dealing with multiple agents passing information back and forth, or when integrating with external tools or APIs.\n\n### What Has Worked for Me\n\nI've found that defining a Pydantic model for each task's output as early as possible really pays off. It forces clarity for both the developer and the LLM, and it ensures that the flow between tasks stays smooth. If something changes in the structure, you can adjust it centrally. This approach has made debugging so much easier and significantly reduced the friction when chaining tasks together in complex workflows.\n\n### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\nfrom typing import Optional, Dict\n\n\nclass EntityExtractionOutput(BaseModel):\n    \"\"\"Extracted entities from the user's input.\"\"\"\n    product: Optional[str] = Field(None, description=\"The name of the product\")\n    location: Optional[str] = Field(None, description=\"Any location reference input\")\n    date: Optional[str] = Field(None, description=\"Relevant date or time information\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example YAML for assigning the model to a task\n# (this would be in your crewai task YAML file)\nextract_entities:\n  description: >\n    Based on the classified intent, extract any relevant entities from \n    the user's input. These may include product names, locations and dates.\n  expected_output: EntityExtractionOutput\n  agent: TBD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example defining the task in your crew\nextract_entities = Task(\n  config=tasks_config['extract_entities'],\n  output_pydantic=EntityExtractionOutput\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keep Agents Focused\n\n### Avoid the \"Do\\-It\\-All\" Agent\n\nA common trap when you're starting with multi\\-agent systems is trying to assign too many different types of tasks to a single agent. It might seem efficient at first. But agents quickly lose their effectiveness when they're overloaded with unrelated responsibilities. Just like in real teams, specialization actually matters. For a [step\\-by\\-step tutorial on building a specialized LLM agent](/article/how-to-build-an-llm-agent-from-scratch-with-gpt-4-react-5), including reasoning, actions, and automation, see our guide using the GPT\\-4 ReAct pattern.\n\n### Group Related Tasks\n\nWhat I've found works best is giving each agent a clear role and limiting them to 3 or 4 closely related tasks. Once you've broken your tasks down into small, focused steps, look at the nature of each task. Group similar ones together and assign them to a single agent. If a task feels out of place or unrelated, it probably belongs to a different agent entirely.\n\n### Push Shared Logic Up to the Agent\n\nSometimes you have certain behaviors or instructions that need to be repeated across multiple tasks. Instead of duplicating that logic in each task, I put it in the agent definition itself. For example, if all of an agent's tasks require a specific tone or reasoning style, I define that expectation once at the agent level. This keeps your task definitions cleaner and reduces inconsistencies during execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handles: classify_intent\nintent_classifier:\n  role: >\n    User Intent Classification Specialist\n  goal: >\n    Accurately identify the user's intent to guide downstream task execution\n  backstory: >\n    You're an expert in natural language understanding with a strong intuition\n    for interpreting human queries. Your precision in classifying intent ensures\n    that the rest of the system can act with clarity and purpose. You never assumeâ€”\n    if the user's intent is unclear, you ask the right follow-up question to \n    clarify it.\n\n# Handles: extract_entities, retrieve_and_respond, log_and_refresh\nretrieval_specialist:\n  role: >\n    Intelligent Retrieval and Response Generator\n  goal: >\n    Deliver precise and well-formatted responses based on user needs\n  backstory: >\n    You're a results-driven AI agent skilled in using structured inputs like\n    classified intent and extracted metadata to retrieve accurate information.\n    You're also a master of markdown formatting, ensuring your answers are always\n    clean, informative, and ready to be presented to the user. You always maintain a\n    helpful, professional tone, and your reasoning is structured and explicitâ€”start \n    from known facts, explain your steps clearly, and avoid skipping \n    logical connections.\n\n    Since many of your tasks require consistent formatting and structured thinking,\n    you've been designed to always follow a markdown-friendly output style,\n    using bullet points, headings, and code blocks where appropriate. You prioritize\n    clarity and readability across all responses, avoiding repetition and verbosity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimize Execution Speed and Flexibility\n\n### The Speed Challenge with Multi\\-Agent Systems\n\nAs you scale up your agents and tasks, one issue that quickly becomes apparent is speed. If every task waits for the previous one to complete, even when they're completely unrelated, you end up with a serious bottleneck. This can slow your system down considerably, especially when tasks could be safely executed in parallel.\n\n### Using Asynchronous and Conditional Tasks\n\nWhat has worked for me is using async\\_execution\\=True for tasks that can run in parallel. If your multi\\-agent system leverages retrieval\\-augmented generation, you might find our guide on [RAG techniques to boost answer accuracy](/article/rag-application-7-retrieval-tricks-to-boost-answer-accuracy-2) especially useful for optimizing both speed and quality. This lets the system take advantage of concurrency without compromising task logic. Tasks that perform independent lookups or data enrichment, for instance, can often be done simultaneously.\n\nI also use context\\-based chaining and conditional tasks to control the flow. Some tasks only need to run if certain outputs are present, and conditional logic makes it easy to skip unnecessary steps. One thing to remember: always end your sequence with a non\\-async task to ensure everything syncs back together before final output or transition.\n\n### Keeping Things Flexible and Fast\n\nThis approach gives you high flexibility and better performance. You're not locked into a rigid step\\-by\\-step structure. You can design your flows to adapt based on what's needed and still move fast. In practice, this has allowed me to scale workflows without sacrificing responsiveness or control.\n\n### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classify_intent:\n  description: >\n    Analyze the user's input and classify it into a predefined intent category\n    (e.g., information request, action request, greeting). If the intent is unclear,\n    ask a clarifying question before proceeding.\n  expected_output: IntentClassificationOutput\n  agent: intent_classifier\n\nextract_entities:\n  description: >\n    Based on the classified intent, extract any relevant entities from the user's \n    input. These may include product names, locations and dates.\n  expected_output: EntityExtractionOutput\n  agent: retrieval_specialist\n  context: [classify_intent]\n\nretrieve_and_respond:\n  description: >\n    Using the classified intent and extracted entities, search the appropriate data\n    sources and generate a markdown-formatted response that directly answers \n    the user query.\n  expected_output: MarkdownResponseOutput\n  agent: retrieval_specialist\n  context: [extract_entities]\n\n# Async Task\nlog_and_refresh:\n  description: >\n    If the user is a premium member, log the query metadata to the analytics system\n    and refresh the corresponding cache entries. This task is optional and should \n    run independently.\n  expected_output: CacheLoggingStatus\n  agent: retrieval_specialist\n  async_execution: true\n  context: [intent_classifier]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conditional Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai.tasks.conditional_task import ConditionalTask\n\n# Output of the classify_intent task\nclass IntentClassificationOutput(BaseModel):\n    intent: str\n    is_premium_user: bool\n        \n# Define the condition function for the conditional task\ndef is_premium_user(output: TaskOutput) -> bool:\n    return output.pydantic.is_premium_user\n    \n# log_and_refresh conditional task\nlog_and_refresh = ConditionalTask(\n    config=tasks_config['log_and_refresh '],\n    output_pydantic=CacheLoggingStatus,\n    condition=is_premium_user\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nMulti\\-agent systems are powerful, but only if they're structured right. The more complex your system gets, the more those small mistakes, like overloading agents or writing unclear tasks, start to compound. For additional guidance on [how to structure system and user prompts to avoid conflicts](/article/system-prompt-vs-user-prompt-how-to-keep-models-from-ignoring-your-rules) and ensure clarity, see our analysis of prompt hierarchies.\n\nWhat has worked best for me is keeping things simple, modular, and easy to reason about. Three to four steps per task, three to four tasks per agent, structured I/O between them, and a framework that lets me adapt quickly when things don't go as planned.\n\nFrameworks like CrewAI and LangChain give you a solid foundation. But the design decisions, how you write your tasks, how you assign your agents, and how you handle execution, that's where the real success or failure happens.\n\nIf you're just starting out, expect to iterate. Expect to refactor. But also know that once the pieces fall into place, multi\\-agent workflows can be incredibly powerful, flexible, and fast to maintain. Hopefully, the patterns I've shared here help you get there a little quicker."
      ]
    }
  ],
  "metadata": {
    "title": "Multi-Agent Systems: A Field Guide with CrewAI and LangChain",
    "description": "Build fast, controllable multi-agent systems using CrewAI and LangChain with task granularity, Pydantic I/O, parallel execution, and focused agents today.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}