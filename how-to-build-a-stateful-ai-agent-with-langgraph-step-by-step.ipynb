{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build a Stateful AI Agent with LangGraph Step-by-Step\n\n**Description:** Build reliable, stateful AI agents with LangGraph using step-by-step patterns, visual debugging, and persistenceâ€”ready for tool use and production today.\n\n**ðŸ“– Read the full article:** [How to Build a Stateful AI Agent with LangGraph Step-by-Step](https://blog.thegenairevolution.com/article/how-to-build-a-stateful-ai-agent-with-langgraph-step-by-step-3)\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you're building AI agents that need to make decisions, call tools, and keep track of context across multiple turns, orchestration becomes absolutely critical. LangGraph gives you a structured way to define agent workflows as state machines, which means you get fine\\-grained control over how your agent reasons, acts, and responds.\n\nIn this tutorial, we're going to build a travel assistant agent that helps users plan trips by calling external tools to fetch weather data and search for flights. You'll learn how to define a stateful graph, integrate tool\\-calling logic, and trace execution step\\-by\\-step. By the end, you'll have a working agent that can handle multi\\-turn conversations and coordinate multiple tools to deliver genuinely useful results.\n\n## Why This Approach Works\n\nLangGraph treats agent workflows as explicit graphs where each node represents a step (like calling the LLM or executing a tool) and edges define transitions. This makes complex agent behavior so much easier to reason about, debug, and extend compared to implicit loops or callback\\-based systems.\n\nHere's what I've found particularly valuable:\n\n* **Explicit state management** â€“ You define exactly what data flows between steps. This makes tracking context and debugging issues straightforward instead of hunting through mysterious state mutations.\n* **Composable logic** â€“ Each node is just a function. You can test individual components, swap them out, or extend them without having to rewrite your entire agent from scratch.\n* **Built\\-in tracing** â€“ LangGraph logs every single state transition, so you can inspect what the agent did at each step and, more importantly, understand why it made those decisions.\n\nThis approach really shines when your agent needs to call multiple tools, handle conditional logic, or maintain conversation history across turns. I've found it particularly useful when building agents that need to coordinate between different data sources.\n\n## High\\-Level Overview\n\nLet me walk you through how the system actually works:\n\n1. **User input** â€“ The user sends a message like \"Find me flights to Tokyo and check the weather\"\n2. **LLM reasoning** â€“ The agent calls the LLM, which decides whether to respond directly or invoke tools\n3. **Tool execution** â€“ If tools are needed, the agent executes them (search\\_flights, get\\_weather) and collects results\n4. **LLM synthesis** â€“ The agent sends tool results back to the LLM, which generates a final response\n5. **Output** â€“ The user receives a natural language answer informed by real data\n\nThe graph has three main nodes that do the heavy lifting:\n\n* **Agent node** â€“ Calls the LLM to decide next actions\n* **Tool node** â€“ Executes requested tools and returns results\n* **Conditional edge** â€“ Routes to tools if needed, or ends if the agent is done\n\n## Setup \\& Installation\n\nThis code runs in Google Colab or any Python 3\\.10\\+ environment. Let's install the dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU langgraph langchain-openai langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your OpenAI API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nos.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace \"your\\-openai\\-api\\-key\" with your actual key. And honestly, for production, please use environment variables or secret management tools instead of hardcoding keys. I learned this the hard way in a previous project.\n\n## Step 1: Define Tools\n\nTools are Python functions decorated with @tool. The LLM can call these functions when it needs external data.\n\nThis example defines two tools: one for searching flights and one for fetching weather. Both return mock data for demonstration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n\n@tool\ndef search_flights(origin: str, destination: str, date: str) -> str:\n    \"\"\"Search for available flights between two cities on a given date.\"\"\"\n    return f\"Found 3 flights from {origin} to {destination} on {date}: Flight A ($450), Flight B ($520), Flight C ($610).\"\n\n@tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get current weather information for a city.\"\"\"\n    return f\"Weather in {city}: 22Â°C, partly cloudy, light breeze.\"\n\ntools = [search_flights, get_weather]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In a real application, you'd replace the return statements with actual API calls to services like Amadeus for flights or OpenWeatherMap for weather data.\n\n## Step 2: Bind Tools to the LLM\n\nThe LLM needs to know which tools are available and how to call them. Use .bind\\_tools() to attach tool schemas to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(model=\"gpt-4o\", temperature=0)\nmodel_with_tools = model.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now when you call model\\_with\\_tools, the LLM can decide to invoke search\\_flights or get\\_weather based on what the user's actually asking for.\n\n## Step 3: Define the Agent State\n\nState is a dictionary that flows through the graph. It holds the conversation history and any other data you need to track."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated\nfrom typing_extensions import TypedDict\nfrom langgraph.graph.message import add_messages\n\nclass State(TypedDict):\n    messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The add\\_messages annotation tells LangGraph to append new messages to the list rather than replacing it. This is crucial â€“ it preserves conversation history across turns so your agent doesn't forget what was discussed earlier.\n\n## Step 4: Build the Agent Node\n\nThe agent node calls the LLM with the current message history. The LLM returns either a text response or a request to call tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_agent(state: State):\n    \"\"\"Invoke the LLM with the current conversation state.\"\"\"\n    response = model_with_tools.invoke(state[\"messages\"])\n    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function takes the state, passes state\\[\"messages\"] to the model, and returns the model's response wrapped in a dictionary. LangGraph then merges it back into the state automatically.\n\n## Step 5: Build the Tool Node\n\nLangGraph provides a ToolNode that automatically executes any tools the LLM requested and formats the results as messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n\ntool_node = ToolNode(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the agent node returns a message with tool\\_calls, the graph routes to this node. It runs the tools and appends their outputs to the message list. Pretty straightforward.\n\n## Step 6: Define Routing Logic\n\nAfter the agent node runs, the graph needs to decide: should it call tools, or is the agent done?\n\nThis function checks if the last message contains tool calls. If yes, route to the tool node. If no, end the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n\ndef should_continue(state: State):\n    \"\"\"Determine whether to call tools or finish.\"\"\"\n    last_message = state[\"messages\"][-1]\n    if last_message.tool_calls:\n        return \"tools\"\n    return END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Assemble the Graph\n\nNow we combine the nodes and edges into a state graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START\n\nworkflow = StateGraph(State)\n\nworkflow.add_node(\"agent\", call_agent)\nworkflow.add_node(\"tools\", tool_node)\n\nworkflow.add_edge(START, \"agent\")\nworkflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\nworkflow.add_edge(\"tools\", \"agent\")\n\ngraph = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let me break down what each line does:\n\n* `add_node(\"agent\", call_agent)` â€“ Registers the agent node\n* `add_node(\"tools\", tool_node)` â€“ Registers the tool execution node\n* `add_edge(START, \"agent\")` â€“ The graph always starts at the agent node\n* `add_conditional_edges(\"agent\", should_continue, ...)` â€“ After the agent runs, route to tools or end based on should\\_continue\n* `add_edge(\"tools\", \"agent\")` â€“ After tools run, return to the agent so it can synthesize results\n\n## Step 8: Run the Agent\n\nInvoke the graph with a user message. The agent will decide which tools to call and return a final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n\nuser_input = \"Find me flights from San Francisco to Tokyo on March 15th and tell me the weather in Tokyo.\"\nresult = graph.invoke({\"messages\": [HumanMessage(content=user_input)]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result dictionary contains the full message history â€“ the user's input, tool calls, tool results, and the agent's final response. Everything's there for you to inspect.\n\n## Step 9: Display Results and Trace\n\nTo see the final answer and understand what happened at each step, print the last AI message and trace all messages.\n\nThis helper function extracts the final AI response and prints a numbered trace showing each message type, content, and metadata like tool calls or tool names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n\ndef print_message_trace(result):\n    final = [m for m in result[\"messages\"] if isinstance(m, AIMessage)][-1]\n    print(final.content)\n\n    print(\"\\nFull Trace:\")\n    for i, m in enumerate(result[\"messages\"], 1):\n        role = type(m).__name__\n        meta = \"\"\n        if isinstance(m, AIMessage) and getattr(m, \"tool_calls\", None):\n            meta = f\" tool_calls={m.tool_calls}\"\n        if isinstance(m, ToolMessage):\n            meta = f\" tool_name={m.name}\"\n        print(f\"{i:02d}. {role}: {m.content}{meta}\")\n\nprint_message_trace(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This trace shows the agent called both tools in parallel, received results, and synthesized a final answer. Actually, the parallel execution is one of my favorite features â€“ it really speeds things up when you need multiple data sources.\n\n## Run and Validate\n\nTest the agent with different inputs to confirm it routes correctly.\n\nSingle tool call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = graph.invoke({\"messages\": [HumanMessage(content=\"What's the weather in Paris?\")]})\nprint_message_trace(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No tool call (direct answer):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = graph.invoke({\"messages\": [HumanMessage(content=\"What is LangGraph?\")]})\nprint_message_trace(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi\\-turn conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = graph.invoke({\"messages\": [HumanMessage(content=\"Find flights to Berlin on April 10th.\")]})\nresult = graph.invoke({\"messages\": result[\"messages\"] + [HumanMessage(content=\"What about the weather there?\")]})\nprint_message_trace(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the multi\\-turn example, the agent maintains context from the first turn and knows \"there\" refers to Berlin. This is exactly the kind of contextual awareness that makes agents feel more natural to interact with.\n\n## Conclusion\n\nYou've built a stateful LangGraph agent that orchestrates tool calls and maintains conversation context. Here's what I think are the key takeaways:\n\n* **State graphs make agent logic explicit** â€“ You control exactly when the LLM is called, when tools run, and how results flow back. No more mysterious behavior buried in callbacks.\n* **Tool binding is straightforward** â€“ Decorate functions with @tool and bind them to the model. The LLM handles the rest. It's honestly simpler than I expected when I first started working with this.\n* **Tracing is built\\-in** â€“ Every message and tool call is logged, making debugging and optimization so much easier than traditional approaches.\n\nFor readers working on data extraction challenges, our guide on building a structured data extraction pipeline with LLMs offers complementary strategies for handling unstructured inputs.\n\nIf you encounter unexpected model behavior, subtle bugs often stem from tokenization issuesâ€”see our article on tokenization pitfalls and invisible characters for actionable solutions.\n\nWhen scaling to long\\-context applications, be aware of memory limitations. Our analysis of context rot and memory management in LLMs explains why models sometimes lose track of earlier information and how to mitigate it.\n\n## Next Steps\n\n* **Add real APIs** â€“ Replace mock data with live calls to flight search APIs (like Amadeus) and weather services (OpenWeatherMap works great)\n* **Persist state** â€“ Use LangGraph's checkpointing to save conversation history to a database, enabling multi\\-session continuity\n* **Add error handling** â€“ Wrap tool calls in try\\-except blocks and return user\\-friendly error messages when APIs fail. Trust me, they will fail at some point.\n* **Deploy as an API** â€“ Serve the graph via FastAPI or Flask so users can interact with it through a web interface or chat app"
      ]
    }
  ],
  "metadata": {
    "title": "How to Build a Stateful AI Agent with LangGraph Step-by-Step",
    "description": "Build reliable, stateful AI agents with LangGraph using step-by-step patterns, visual debugging, and persistenceâ€”ready for tool use and production today.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}